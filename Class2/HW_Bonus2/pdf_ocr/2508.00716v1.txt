2508.00716v1 [cs.LG] 1 Aug 2025

arXiv

Nested Graph Pseudo-Label Refinement for Noisy Label
Domain Adaptation Learning

Yingxu Wang!, Mengzhu Wang’, Zhichao Huang’, Suyu Liu*

"Mohamed bin Zayed University of Artificial Intelligence

"Hebei University of Technology

3JD Industrial Nanyang Technological University

yingxv.wang @ gmail.com,

Abstract

Graph Domain Adaptation (GDA) facilitates knowledge
transfer from labeled source graphs to unlabeled target graphs
by learning domain-invariant representations, which is essen-
tial in applications such as molecular property prediction and
social network analysis. However, most existing GDA meth-
ods rely on the assumption of clean source labels, which
rarely holds in real-world scenarios where annotation noise is
pervasive. This label noise severely impairs feature alignment
and degrades adaptation performance under domain shifts.
To address this challenge, we propose Nested Graph Pseudo-
Label Refinement (NeGPR), a novel framework tailored for
graph-level domain adaptation with noisy labels. NeGPR first
pretrains dual branches, i.e., semantic and topology branches,
by enforcing neighborhood consistency in the feature space,
thereby reducing the influence of noisy supervision. To bridge
domain gaps, NeGPR employs a nested refinement mech-
anism in which one branch selects high-confidence target
samples to guide the adaptation of the other, enabling pro-
gressive cross-domain learning. Furthermore, since pseudo-
labels may still contain noise and the pre-trained branches
are already overfitted to the noisy labels in the source do-
main, NeGPR incorporates a noise-aware regularization strat-
egy. This regularization is theoretically proven to mitigate the
adverse effects of pseudo-label noise, even under the pres-
ence of source overfitting, thus enhancing the robustness of
the adaptation process. Extensive experiments on benchmark
datasets demonstrate that NeGPR consistently outperforms
state-of-the-art methods under severe label noise, achieving
gains of up to 12.7% in accuracy.

Introduction

Graph Domain Adaptation (GDA) (You et al. 2022; Cai et al.
2024) has emerged as a prominent technique for leverag-
ing labeled graph data from a source domain to enhance
learning on an unlabeled target graph domain. Its efficacy
has been demonstrated across diverse applications, includ-
ing temporally-evolved social network analysis (Wang et al.
2021, 2024c; Yao et al. 2023), molecular property predic-
tion (Zhu et al. 2023; Yin et al. 2024c), and protein-protein
interaction modeling (Cho, Berger, and Peng 2016; Wang
et al. 2024a). The core paradigm typically involves learning
domain-invariant node/graph representations that bridge the
distributional shift between source and target domains, thus
enabling effective inference on the target data.

dreamkily @ gmail.com,

iceshzc@gmail.com, suyu.liu @ntu.edu.sg

However, the success of standard GDA methods crucially
relies on the accurately labeled source data. In practice,
source domain labels are often corrupted by noise arising
from annotation errors (Dai, Aggarwal, and Wang 2021;
Yuan et al. 2023b), subjective judgments (Platanios, Dubey,
and Mitchell 2016; Yin et al. 2024d), or inherent ambigu-
ities in data collection (Chen, Shah, and Kyrillidis 2020;
Wang et al. 2024b). This prevalent issue of label noise can
severely misguide the learning of domain-invariant repre-
sentations (Li, Socher, and Hoi 2020; Yin et al. 2024b),
leading to suboptimal or even detrimental adaptation per-
formance on the target domain (Yin et al. 2025; Wang et al.
2025). Existing noise label learning methods typically rely
on loss function design to mitigate the impact of noisy la-
bels (Han et al. 2018; Natarajan et al. 2013), which se-
lects clean instances for joint training, and robust loss func-
tions (Wei et al. 2020; Li, Socher, and Hoi 2020), which
leverage small-loss selection or instance mixture models.
While effective in controlled settings, these approaches fall
short in the presence of domain shifts. The coexistence of
distribution shift and label noise leads to misaligned fea-
ture spaces, causing noise-robust losses to erroneously align
clean features with noisy targets, thereby amplifying neg-
ative transfer (Yu et al. 2020; Yin et al. 2022a). While re-
cent efforts have been made to address GDA under noisy
labels (Yuan et al. 2023a; Wang and Yang 2022), they pri-
marily target node classification tasks, leaving a critical gap
in addressing graph-level scenarios. Many real-world ap-
plications, such as molecular property prediction (Stokes
et al. 2020) and social network analysis (Hamilton, Ying,
and Leskovec 2017), inherently depend on graph-level clas-
sification, where label noise can severely compromise the
identification of functional groups and the modeling of com-
munity behaviors. The lack of attention to graph-level adap-
tation under noisy labels significantly limits the practical ap-
plicability of existing methods in high-impact domains.

In this paper, we investigate the development of an effi-
cient GDA framework for scenarios involving label noise.
However, designing such a framework poses several funda-
mental challenges: (1) Distribution shift undermines loss-
based denoising. Conventional noise-robust loss functions
are primarily designed for specific domains and often strug-
gle under distribution shifts. In the presence of noisy la-
bels in the source domain, aligning target features with cor-


rupted source representations can lead to noise-aligned em-
beddings, degrading generalization due to feature misalign-
ment and increased risk of negative transfer. Recent stud-
ies in GDA have highlighted that noisy supervision severely
hinders feature alignment across domains, especially when
relying on pseudo labels or unreliable source signals (Yuan
et al. 2023a). These findings underscore the need for noise-
aware mechanisms that explicitly account for both label
noise and domain discrepancy. (2) Imperfect pseudo labels
compromise domain adaptation. Probability-based pseudo-
labeling has shown promise in bridging distribution shift and
mitigating supervision noise (Yuan et al. 2023a; Yin et al.
2023a). However, the reliability of selected pseudo labels is
often compromised by erroneous source annotations, lead-
ing to residual noise being transferred into the target do-
main. In Graph Neural Networks (GNNs), such corrupted
pseudo labels can propagate through message passing, trig-
gering self-reinforcing error cascades. As each GNN layer
aggregates information from potentially mislabeled neigh-
bors, the accumulated noise progressively deteriorates local
neighborhood structures and distorts global representations
over successive adaptation rounds (Wang et al. 2024d). (3)
Label noise impairs distribution alignment in GDA. Exist-
ing methods typically adopt explicit (Long et al. 2015) or
implicit (Long et al. 2018) strategies to align feature dis-
tributions across domains. However, significant label noise
corrupts supervision signals, causing samples to drift to-
ward incorrect class regions and disrupting the formation
of domain-invariant features. This misalignment undermines
the effectiveness of domain discriminators and hampers re-
liable adaptation. These challenges call for a unified frame-
work that combines noise-robust representation learning,
trustworthy pseudo-label refinement, and alignment strate-
gies that preserve class-level semantics across domains.

To tackle these challenges, we propose Nested Graph
Pseudo-Label Refinement (NeGPR), a novel framework de-
signed for GDA under noisy labels. To effectively disentan-
gle the impact of label noise from domain distribution shift,
NeGPR first pre-trains noise-resilient models from implicit
and explicit perspectives by enforcing semantic consistency
among neighboring samples in the feature space. The im-
plicit branch promotes feature-level consistency based on
learned representations, while the explicit branch captures
structural patterns by leveraging graph topology. This dual-
perspective design improves robustness to noisy supervision
and provides a reliable foundation for domain adaptation.
Then, to align the domain distribution, NeGPR iteratively
leverages cross-branch knowledge, where one branch filters
highly reliable target domain samples, and the other branch
is fine-tuned accordingly, enabling mutual enhancement and
progressive adaptation. However, the filtered pseudo-labels
may still contain erroneous category information, and the
pre-trained branches have already overfitted to the label
noise in the source domain. The interplay of these two fac-
tors exacerbates performance degradation during domain
adaptation. To tackle this, NeGPR employs a regulariza-
tion along with a theoretical analysis demonstrating its ef-
fectiveness in suppressing the influence of noisy pseudo-
labels. Extensive experiments demonstrate that NeGPR sig-

nificantly outperforms state-of-the-art methods under severe
label noise. Our main contributions are summarized as:

e We investigate a novel problem setting, graph domain
adaptation learning under label noise, where label noise
and domain shift coexist and jointly pose significant chal-
lenges for graph representation learning.

We propose NeGPR, a dual-branch framework that in-
tegrates noise-resilient pre-training, nested pseudo-label
refinement, and theoretically grounded regularization to
tackle graph domain adaptation under label noise.

We evaluate NeGPR on extensive datasets, showing that
NeGPR significantly outperforms existing approaches
under various noise levels and domain shift scenarios.

Related work

Graph Domain Adaptation. Graph Domain Adaptation
(GDA) has emerged as a critical research topic, aiming to
leverage labeled source domain graphs to enable robust rep-
resentation learning on unlabeled or sparsely labeled target
graphs (Lin et al. 2023; Luo et al. 2023; Liu et al. 2024a). To
achieve this, most existing approaches first employ Graph
Neural Networks (GNNs) (Kipf and Welling 2017a; Chen
et al. 2023) to generate representations for each graph (Wu,
Pan, and Zhu 2022; Zhu et al. 2021; Yin et al. 2022b). They
then commonly use adversarial learning to implicitly align
feature distributions and reduce domain discrepancies, apply
pseudo-labeling to iteratively refine predictions in the target
domain, or incorporate structure-aware strategies to explic-
itly align graph-level semantics and topological structures,
thereby improving generalization across diverse graph do-
mains (Yin et al. 2023b; Wang et al. 2024b; Liu et al. 2024b).
However, these methods often overlook the impact of noisy
labels, which can distort learned representations and lead
to misaligned distributions and unreliable predictions in the
target domain. Although a few label-denoising GDA meth-
ods have been proposed, they primarily focus on node-level
tasks (Yuan et al. 2023a). To address these limitations, we
propose a novel label-denoising domain adaptation method
designed for graph-level classification tasks.

Learning with Noise Labels. Learning with noisy labels
has garnered significant attention for its crucial role in de-
veloping robust models under imperfect supervision, which
has been widely used in machine learning and computer vi-
sion (Zhu et al. 2024). Existing methods typically address
label noise by employing robust loss functions, identifying
and filtering out noisy samples, or refining labels through
correction mechanisms (Feng et al. 2021; Xu et al. 2025).
However, existing methods still insufficiently investigate the
interplay between label noise and domain adaptation (Yin
et al. 2024a; Zhu et al. 2024). In particular, applying a model
trained on the source domain to the target domain can be
regarded as a noisy inference process due to distributional
shifts inherent in domain adaptation (Yu et al. 2020; Dan
et al. 2024). Furthermore, label noise in the source domain
can also degrade model performance (Yuan et al. 2023a; Yu
et al. 2024). Critically, conventional methods cannot disen-
tangle whether the observed performance degradation is pri-
marily attributable to domain shift or label noise, thereby


Implicit
Extraction
Branch

3
S|
8
N
&
:
Qa

Explicit
Extraction
Branch

Top-k(G;)

Target Graph Data

Noisy Pseudo-Label

Explicit Tolerated Regularization

> Tang > Extraction |—> | Lrerine
Branch
me Noisy
zB Direction
iS}
"3 Nested Pseudo-Label Refinement Correct
Direction
= - Tolerated
Implicit Regularization
Extraction |—> Lye rine
Branch

&
=> 72,

Figure 1: Overview of the proposed NeGPR. NeGPR consists of a dual-branch pretraining module that captures complementary
semantic and structural features under label noise. Then, a nested pseudo-label refinement module alternately selects high-
confidence target samples from one branch to guide the other, enabling progressive cross-domain adaptation. The noisy pseudo-
label tolerated regularizatio penalizes overconfident predictions to suppress the effect of noisy pseudo labels.

limiting their ability to address the underlying causes of
adaptation failure effectively. To address this challenge, we
propose a novel learning framework designed to mitigate the
effects of domain shift and label noise.

Methodology
Overview of Framework

This work studies the problem of unsupervised graph do-
main adaptation in the presence of noisy labels and proposes
a novel framework, NeGPR, as illustrated in Fig. 1. NeGPR
comprises three key components: (1) Noise-Resilient Dual
Branches Pre-Training. To effectively suppress the im-
pact of label noise, we first pre-train noise-resilient mod-
els from implicit and explicit perspectives by enforcing
semantic consistency among neighboring samples in the
feature space; (2) Nested Pseudo-Label Refinement. To
align category-level distributions, each branch selects high-
confidence pseudo-labeled target samples based on predic-
tion confidence and uses them to fine-tune the other branch.
This cross-branch refinement mitigates error accumulation
from noisy pseudo labels and enables progressive domain
adaptation through mutual supervision; (3) Noisy Pseudo-
Label Tolerated Regularization. To alleviate the negative
impact of noisy pseudo labels, we introduce a noise-aware
regularization term with theoretical guarantees. This regu-
larization effectively suppresses error propagation induced
by noisy pseudo labels during the adaptation process.

Problem Formulation

Given a graph G = (V,€, X) with the set of nodes V and
edges € C V x V. The X € R'”!*4 is the node feature ma-
trix, where each row x, € R® denotes the feature of node
v € V, |V| is the number of nodes, and d denotes the di-
mension of node features. In our setting, we have access to
a labeled source domain D* = {(G3, y?)})'8, with n, sam-
ples, where the labels y? may be corrupted by noise, and
an unlabeled target domain D' = {GU }"", with n, sam-
ples. Both domains share the label space VY = {1,2,--- ,C}
but follow different data distributions. The goal is to train

the graph classification model using both D* and Dé and
achieve high accuracy on the target domain.

Noise-Resilient Dual Branches Pre-Training

To mitigate the adverse impact of noisy labels in the source
domain, we adopt a dual-branch architecture that captures
semantic consistency from implicit and explicit perspec-
tives. Noisy supervision can distort the feature space by
pulling semantically similar graphs toward incorrect class
boundaries. In contrast, the local relationships among neigh-
boring samples often remain reliable despite label corrup-
tion. Motivated by this, we construct two parallel branches
that exploit neighborhood consistency to learn robust repre-
sentations. One branch captures semantic similarity through
learned features, while the other incorporates structural in-
formation derived from graph topology. This design en-
hances the model’s resilience to noise and provides a stable
foundation for subsequent domain adaptation.

Implicit Extraction Branch. The implicit branch follows
the MPNNs mechanism (Gilmer et al. 2017), which extracts
graph semantics by aggregating neighborhood representa-
tions to update the central node embeddings. Specifically,
we update the embedding of node wu at layer / and then sum-
marize the node embeddings into graph-level:

hi, =COM (ni, AGG (BSven))
2? =RBADOUT ({ht}.,-y).

where (wu) is the neighbours of node u. COM and
AGG denote the combination and aggregation operations,
READOUT is the graph pooling function. This formulation
allows the implicit branch to capture structural information
indirectly through supervised learning with noisy labels.

Explicit Extraction Branch. While the implicit branch cap-
tures structural semantics indirectly, its performance may
deteriorate under domain shifts due to limited sensitivity to
distributional changes. To enhance structural awareness, we
introduce a complementary branch that explicitly encodes
topological information by extracting high-order subgraph
patterns (Shervashidze et al. 2011; Nikolentzos, Siglidis, and


Vazirgiannis 2021). This design enables the model to gener-
ate graph-level representations that are more robust to struc-
tural discrepancies across domains. Specifically, we formu-
late the explicit extraction branch as:

h, = (Sv (G)), Wey,
223 — READOUT ({hy},cy)

where S,(G) denotes a set of high-order substructures ex-
tracted from G (e.g., shortest paths (Borgwardt and Kriegel
2005) or subtree patterns (Shervashidze et al. 2011)),
@(-) encodes each substructure into a latent representation,
and READOUT(-) aggregates these representations into a
graph-level embedding. The resulting Zé? serves as the ex-
plicit topological representation of the graph.
Noise-Resilient Pre-Training. To mitigate the impact of la-
bel noise in the source domain, we exploit local seman-
tic consistency among graphs in the feature space. Empir-
ically, semantically similar graphs tend to exhibit stable fea-
ture distributions, even under corrupted labels (Wang and
Isola 2020; Iscen et al. 2022). Based on this insight, we con-
struct a semantic neighbor graph by identifying the top-k
nearest neighbors for each source sample using similarity
aj = 2B 2B /\|28. (2G, ll over graph-level embed-
dings obtained from each branch, where B € {IB, EB}.
To enforce prediction consistency within local neighbor-
hoods, we encourage the predicted distribution to align with
a weighted average of its semantic neighbors’ predictions:

S B
aij: ZG; 5

j€etop—k(G;)

1
B _ B
Le. = S KL | 2,
Ns « 1
4

where KL is the Kullback-Leibler divergence, top—k(G;) is
the top-k nearest neighbors samples of G;. This regulariza-
tion guides the model to learn noise-resilient representations
by aligning each prediction with its semantic context, rather
than relying solely on potentially corrupted labels. In formu-
lation, we pre-train the dual branches with:

Lite = Leap + BL vise: (1)

sup
where LE, = x i (o(2G, ), yi) is the supervised clas-
sification loss, / is the cross-entropy loss and a is the softmax
function. B € {IB,EB} indicates the implicit and explicit
branches pre-training.

Nested Pseudo-Label Refinement

While various domain adaptation techniques such as distri-
bution alignment (Long et al. 2015; Ganin et al. 2016) and
adversarial training (Tzeng et al. 2017; Pei et al. 2018) have
been widely explored, they often rely on strong assumptions
regarding the existence of domain-invariant representations,
which may not hold in the presence of label noise. In con-
trast, pseudo-labeling provides a flexible and data-driven al-
ternative by leveraging model predictions on unlabeled tar-
get samples to guide adaptation (Lee et al. 2013; Xie et al.
2020). In our setting, the dual-branch encoder offers two
complementary perspectives for estimating target seman-
tics, enabling more reliable pseudo-label selection through

confidence-based filtering. This design facilitates progres-
sive adaptation by gradually incorporating trustworthy tar-
get samples into training, while retaining the robustness of
the noise-resilient pre-trained branches.

Specifically, at each iteration of cross-branch pseudo-
label refinement, we select one branch to generate pre-
dictions for all target domain samples. For each sample
Gi € D*, we compute the predicted class probability vector

yj = Softmax(z@, ), where B € {IB, EB}. We then select
a set of high-confidence samples Jeong defined as:

The = {Ge D* | max(y;) > ¢}, (2)

where ¢ is a pre-defined threshold. The corresponding
pseudo-labels are assigned as: yj = arg max(y;), VG) €
TG; The selected pseudo-labeled samples {(G%,, j;)}, are
then used to fine-tune the other branch with:

, , 1 ~ /
Line = Lhe ~~ \72 | S> Yj log o(2G ), (3)
conf cterB

conf

where o(zB,) denotes the predicted probability from the

other branch B’ and o is the Softmax operation. The two
branches are alternated in subsequent iterations, allowing the
model to progressively adapt through mutual supervision.

Noisy Pseudo-Label Tolerated Regularization

Pseudo-labeling facilitates adaptation to the target domain
by providing surrogate supervision, yet it inevitably in-
troduces label noise that may compromise model perfor-
mance (Rizve et al. 2021). To address this issue, we propose
a noise-aware regularization term that penalizes overconfi-
dent or unstable predictions during refinement. This regular-
ization serves as a soft constraint to suppress the influence
of unreliable pseudo-labels, guiding the model toward more
consistent and robust predictions. Moreover, we provide a
theoretical analysis, which guarantees its ability to mitigate
the negative impact of noisy supervision and enhance gen-
eralization in the target domain. Specifically, we define the
refinement loss with the noisy tolerated regularization as:

Y> tos ((o(@8:), (28))) .

conf

, _ B’ Xv
LRe =Lrefine — \72
conf! Gg

where (o(22, ),o(z2,)) denotes the inner product between
J Jd

the softmax predictions of the two branches. Here, o repre-
. /
sents the Softmax function, and zee ; Zi are the graph-level
J Jd

embeddings of Gi produced by branches B’ and B, respec-
tively. B, B’ € {IB, EB} with B 4 B’. For future analysis
of the effectiveness of noisy-tolerant regularization, we de-
rive the gradient of Eq. (4) and introduce Lemma 1.

Lemma 1 Let 0 denote the parameters of branch B’. The
gradient of Eq. 4 with respect to O is given by:

1 , _
TE] So Vo2d: «(pj — Gj +A+8;),
| conf ater B 7

conf

Vole. =


where pj = o (2G , a = 0 (2G ), and the regularization

gradient g; € R° is defined as:

1 +
8) = —— > Sp; Gi
4 (Pj, Gj) pi’
jk

Here, 6% denotes the Kronecker delta, which equals 1 if c =
k and 0 otherwise.

Algorithm 1: Nested Pseudo-Label Refinement (NeGPR)

Input: Source domain data D, = {(G%,y?)}, target do-
main data D; = {G‘}, number of iterations T

Output: Trained model parameters O for implicit branch
(IB) and O’ for explicit branch (EB)
/Stage 1: Dual Branches Pre-Training/

: for B, B’ € {IB, EB}, B 4 B’ do

Update O with Eq. (1)

Update ©’ with Eq. (1)

: end for
/Stage 2: Nested Refinement with
Regularization/

5: fori = 1 to T do

6: Filter high-confidence samples 7,

with Eq.(2)
7: Update ©’ of EB branch by Eq. (4)

BRYN

B

onf £rom branch B

8: Filter high-confidence samples TB. from branch B’
with Eq.(2)
9: Update © of IB branch by Eq. (4)
10: end for

11: return Dual branches parameters © and 0’

From Lemma 1, we observe that when the pseudo label
yj is correct, the prediction p; increasingly aligns with it
during training, causing the cross-entropy gradient to dimin-
ish. This reduction weakens the learning signal from clean
samples and allows noisy examples to dominate the opti-
mization. The regularization term g; alleviates this issue by
maintaining substantial gradient contributions for clean in-
stances, thus preserving their supervisory effect even as the
loss converges. When 4; is incorrect, the cross-entropy term
Pp; — y; becomes positive, leading to updates that push the
model away from the true class. The regularization term g;,
which is typically negative at the true class index, counter-
acts this effect by reducing the gradient magnitude on mis-
labeled examples. This dampening mechanism limits the in-
fluence of noisy labels during optimization.

Learning Framework

The overall learning framework is outlined in Algorithm 1,
which adopts an alternating dual-branch strategy to pro-
gressively refine pseudo labels and suppress the influence
of label noise. The process begins with noise-resilient pre-
training on the source domain to initialize both the implicit
and explicit branches (lines 1-3). At each iteration, one
branch generates pseudo labels for the target domain, and

high-confidence samples are selected based on prediction
probability (lines 6 and 8). These samples are then used to
update the other branch via a regularized training objective
(lines 7 and 9). The two branches alternate roles throughout
training (lines 5-10), enabling mutual correction and pro-
moting robust adaptation under noisy supervision.

Experiments
Experimental Settings

Datasets. To assess the effectiveness of the proposed
NeGPR, we conduct extensive experiments on multiple
benchmark datasets from TUDataset, covering diverse types
of domain shifts. For structure-based domain shifts, we uti-
lize MUTAGENICITY (Kazius, McGuire, and Bursi 2005),
NCI1 (Wale, Watson, and Karypis 2008), FRANKEN-
STEIN (Orsini, Frasconi, and De Raedt 2015), and PRO-
TEINS (Dobson and Doig 2003), where each dataset is par-
titioned into source and target domains based on variations
in edge, node and graph flux density to simulate structural
distribution shifts (Yin et al. 2023b). For feature-based do-
main shifts, we evaluate NeGPR on PROTEINS, DD, BZR,
BZR_MD, COX2, and COX2_MD (Sutherland, O’ brien, and
Weaver 2003), where domain discrepancies primarily arise
from differences in semantic feature distributions. Detailed
dataset statistics are provided in Appendix C.

Baselines. We compare the proposed NeGPR with a com-
prehensive set of competitive baselines on the datasets
above. These baselines include two graph kernel methods:
WL (Shervashidze et al. 2011) and PathNN (Michel et al.
2023); four general graph neural networks: GCN (Kipf and
Welling 2017b), GIN (Xu et al. 2018), GAT (Veli¢kovié
et al. 2018), and GMT (Baek, Kang, and Hwang 2021);
five label denoising methods: Co-teaching (Han et al. 2018),
RTGNN (Qian et al. 2023), Taylor-CE (Feng et al. 2021),
OMG (Yin et al. 2023c), and SPORT (Yin et al. 2024a);
six graph domain adaptation methods: DEAL (Yin et al.
2022b), CoCo (Yin et al. 2023b), SGDA (Qiao et al. 2023),
A2GNN (Liu et al. 2024a), StruRW (Liu et al. 2023), and
PA-BOTH (Liu et al. 2024b); and two methods that address
both label noise and domain adaptation: ALEX (Yuan et al.
2023a) and ROAD (Feng et al. 2023). More detailed descrip-
tions of the baseline settings are provided in Appendix D.
Implementation Details. We implement NeGPR and all
baseline models using PyTorch and conduct all experiments
on NVIDIA A100 GPUs to ensure a fair comparison. For
NeGPR, the implicit branch (IB) is instantiated with the
GMT (Baek, Kang, and Hwang 2021) architecture to cap-
ture semantic consistency via message passing, while the ex-
plicit branch (EB) employs the PathNN model (Michel et al.
2023) to extract high-order topological structures explicitly.
Both branches use 4 GNN layers, with a hidden dimension
of 256 and a weight decay of 10~!*. The models are trained
using the Adam optimizer with a learning rate of 1074. All
the models are trained on noisy labeled source graphs and
evaluated on unlabeled target graphs. We set the noise ratio
a = 0.3 and the pseudo-label threshold ¢ = 0.9 by default.
All reported results are averaged over five independent runs.


Table 1: The graph classification results (in %) on the PROTEINS dataset under graph flux density domain shift (source >
target). PO, P1, P2 and P3 denote the sub-datasets partitioned with graph flux density. Bold results indicate the best performance.

Methods PO-—P1 | PI-—PO | PO-+P2 | P2-—+P0 | PO-+P3 | P3-—>PO | P1-—P2 | P2—P1 | PI-P3 | P3-P1 | P2—P3 | P3->P2
WL 67.5414 | 31.9419 | 54.7408 | 67.0415 | 24.2424 | 21.6418 | 49.841.0 | 43.3417 | 33.4419 | 61.2413 | 32.9408 | 43.6421
PathNN 68.0414 | 72.642.6 | 55.1423 | 38.2428 | 25.4425 | 22.6446 | 39.9431 | 63.6417 | 34.4425 | 27.642.2 | 67.041.9 | 46.742.0
GCN 67.343.5 | 73.3443 | 55.941.7 | 72.1426 | 23.8417 | 22.5414 | 52.343.9 | 63.9424 | 27.341.0 | 45.641.7 | 30.3421 | 47.7414
GIN 62.3423 | 59.5425 | 50.642.1 | 49.4424 | 24.8413 | 60.0409 | 45.2403 | 56.443.1 | 66.041.2 | 34.3417 | 33.4414 | 48.541.9
GAT 62.8+0.8 | 68.141.2 | 50.141.7 | 66.2414 | 64.6423 | 18.0414 | 48.941.0 | 62.8418 | 46.5414 | 25.5411 | 33.1409 | 49.0427
GMT 49.6+1.0 | 51.3413 | 54.1416 | 50.6413 | 53.8411 | 51.441.7 | 52.9419 | 53.0411 | 53.5+1.0 | 50.4+1.1 | 52.541.2 | 50.2+1.0
Co-teaching | 67.4+0.5 | 69.2412 | 54.2417 | 69.4104 | 24.7419 | 25.5413 | 49.4408 | 61.4426 | 38.9421 | 47.4425 | 43.0418 | 46.443.3
Taylor-CE 65.743.6 | 66.444.3 | 49.3435 | 53.642.9 | 27.9415 | 57.4424 | 50.642.2 | 42.7418 | 69.7419 | 39.6417 | 40.4413 | 42.0427
RTGNN 63.041.8 | 70.341.2 | 61.141.8 | 67.7425 | 26.0407 | 20.0409 | 55.1414 | 67.3417 | 24.4413 | 48.9415 | 34.8412 | 44.041.5
OMG 64.9414 | 72.24+1.7 | 47.141.1 | 63.3419 | 68.1413 | 22.3408 | 46.3423 | 59.3422 | 52.5418 | 21.8419 | 35.1415 | 43.641.3
SPORT 60.7414 | 65.441.8 | 49.041.2 | 69.1405 | 54.7411 | 51.8415 | 55.3421 | 64.3424 | 51.641.3 | 25.841.2 | 34.1417 | 42.3419
CoCo 66.9413 | 50.9+1.9 | 55.2415 | 64.4414 | 71.4417 | 25.941.2 | 51.6426 | 55.1424 | 36.7418 | 56.341.2 | 38.341.9 | 44.5+43.0
DEAL 66.7423 | 71.6421 | 55.241.9 | 70.443.0 | 34.741.0 | 58.641.7 | 51.042.0 | 65.3416 | 43.7418 | 66.541.9 | 63.443.1 | 46.4423
SGDA 67.8+2.1 | 59.4413 | 57.7416 | 73.1418 | 38.3424 | 31.942.7 | 48.242.0 | 48.8422 | 39.242.0 | 58.641.6 | 40.2418 | 46.8423
A2GNN 60.7+2.2 | 65.541.8 | 54.342.0 | 67.542.2 | 60.241.9 | 53.3417 | 44.2415 | 63.1418 | 42.9423 | 35.7425 | 46.542.0 | 53.8421
StruRW 62.5421 | 72.9414 | 59.2418 | 71.042.0 | 39.8419 | 34.9421 | 49.641.6 | 66.642. 37.4423 | 61.1417 | 40.5415 | 45.9422
PA-BOTH 64.9+1.7 | 73.642.1 | 58.042.2 | 69.1419 | 36.5423 | 54.3415 | 53.941.8 | 67.2414 | 42.2416 | 67.642.0 | 63.1419 | 45.3421
ROAD 52.2+2.6 | 53.8+3.2 | 60.942.7 | 55.9421 | 63.142.0 | 57.242.7 | 58.6424 | 58.2417 | 62.542.0 | 58.241.8 | 61.1425 | 57.2417
ALEX 68.742.7 | 74.943.0 | 62.5428 | 68.642.6 | 73.7428 | 61.3434 | 62.8426 | 64.942. 68.2+2.0 | 61.7422 | 64.143.0 | 58.0+2.2
NeGPR 71.742.4 | 74.742.6 | 64.5421 | 73.3421 | 77.1424 | 63.241.7 | 63.8425 | 68.1422 | 70.5421 | 68.4424 | 67.2423 | 61.041.6

Table 2: The graph classification results (in %) under se-
mantic information shift (source—target). P, D, C, CM, B,
and BM denote PROTEINS, DD, COX2, COX2_MD, BZR,
and BZR_MD, respectively. Bold indicates the best perfor-
mance. OOM means out of memory.

Methods PD DP CCM | CM->C | B>BM | BM->B
WL 42.5420 | 43.6424 | 50.7415 | 54.8420 | 50.6422 | 25.3423
PathNN 47.5415 | 41.142.0 | 49.8+16 | 66.9426 | 50.3416 | 37.2424
GCN 53.7423 | 51.842.0 | 49.8+1.6 | 32.742.9 | 49.742.1 | 55.542.7
GIN 48.3419 | 49.941.7 | 51.2+2.0 | 52.6425 | 48.742.0 | 55.8419
GAT 59.2417 | 57.4+2.0 | 49.3421 | 36.4425 | 51.341.9 | 32.742.0
GMT 55.7425 | 53.9426 | 50.7421 | 44.4419 | 49.2417 | 32.7422
Co-teaching | 55.9422 | 60.14+1.8 | 47.7423 | 48.812.0 | 50.8424 | 44.2119
Taylor-CE 55.242.0 | 55.742.2 | 51.2418 | 55.642.5 | 48.742.0 | 44.2419
RTGNN 53.742.0 | 52.641.9 | 51.2+2.0 | 54.3416 | 49.2428 | 55.5423
OMG 56.7417 | 53.4422 | 54.5418 | 57.3427 | 50.8+2.0 | 59.3423
SPORT OOM OOM 53.742.1 | 63.943.3 | 51.4+2.6 | 65.8+3.0
CoCo 62.6425 | 67.1+2.0 | 56.8+2.5 | 67.0428 | 50.5+2.0 | 79.342.2
DEAL 69.7419 | 60.0425 | 52.7421 | 60.442.2 | 52.442.9 | 68.6+42.8
SGDA 53.3419 | 55.2433 | 54.1428 | 52.642.7 | 49.6424 | 48.342.1
A2GNN 61.6429 | 68.842.7 | 51.24+2.0 | 65.442.5 | 52.1427 | 61.1427
StruRW 52.8419 | 56.4433 | 52.8428 | 51.342.7 | 48.7424 | 49.743.1
PA-BOTH 56.5429 | 54.2426 | 51.24+2.9 | 58.9423 | 48.742.7 | 47.742.5
ROAD 55.242.0 | 59.543.0 | 55.2+2.6 | 70.242.7 | 52.742.1 | 79.0423
ALEX 68.842.1 | 68.1422 | 56.2+2.0 | 69.2429 | 54.342.1 | 78.8+3.0
NeGPR 72.342.6 | 69.9428 | 57.342.6 | 73.0423 | 55.9+3.0 | 80.0+2.7

Performance Comparison

We present the results of the proposed NeGPR with all base-
line models under the setting of graph domain adaptation
on different datasets in Tables 1, 2, and 8-18. From these
tables, we observe that: (1) Label denoising methods con-
sistently outperform general graph-based approaches, as the
presence of noisy labels significantly impairs the perfor-
mance of standard graph models lacking dedicated noise-
handling mechanisms. (2) Graph domain adaptation meth-
ods generally outperform graph-based and label-denoising

approaches by effectively mitigating domain distribution
shifts. However, their performance may still degrade when
source labels are corrupted, highlighting the need for meth-
ods that jointly address domain shift and label noise specific
for graphs. (3) Label denoising domain adaptation meth-
ods demonstrate superior performance over graph domain
adaptation methods, which highlights the importance of ex-
plicitly addressing label noise alongside domain alignment
to enhance model generalization in noisy cross-domain set-
tings. (4) The proposed NeGPR consistently achieves the
highest performance across datasets in most cases, demon-
strating its superiority. The outstanding performance is at-
tributed primarily to two factors: (i) the integration of im-
plicit branch and explicit branch enables comprehensive ex-
traction of both structural and semantic features, substan-
tially enhancing representation quality and classification ac-
curacy; and (ii) the nested refinement and noisy tolerated
regularization modules jointly promote robust cross-domain
adaptation by progressively selecting reliable supervision
and suppressing noisy signals. Additional results on other
datasets are provided in Appendix E.

Ablation Study

We conduct ablation studies to examine the contributions of
each component in the proposed NeGPR: (1) NeGPR w/o
IB: It removes the implicit extraction branch; (2) NeGPR
w/o EB: It removes the explicit extraction branch; (3)
NeGPR w/o NRL: It removes the noise resilient loss in the
pretraining stage; (4) NeGPR w/o NTR: It remove the noisy
pseudo-label tolerated regularization loss during fine-tuning.

Experimental results are reported in Table 3, 5-7. From
the results, we find that: (1) NeGPR outperforms NeGPR
w/o IB and NeGPR w/o EB, underscoring the importance
of integrating implicit and explicit branches that capture
semantic and structural information. Their joint modeling


Table 3: The results of ablation studies on the PROTEINS dataset (source — target). Bold results indicate the best performance.
Methods | PO-+P1 | P1--PO | PO--P2 | P2—PO | PO--P3 | P3->PO | Pl-+P2 | P2—+P1 | P1-P3 | P3-P1 | P2—P3 | P3-P2
NeGPR w/o IB 50.8 50.6 50.7 52.2 50.0 48.6 52.0 52.2 47.7 50.8 52.5 50.3
NeGPR w/o EB 50.4 52.1 49.0 52.1 49.0 51.6 46.5 50.4 51.6 50.4 53.3 49.9
NeGPR w/o NRL 68.5 71.4 62.5 70.0 73.6 60.9 61.2 65.2 68.4 64.6 63.8 58.4
NeGPR w/o NTR 69.7 71.0 63.8 70.3 74.8 62.4 62.4 66.2 69.0 65.5 65.8 58.9
NeGPR | 7.7 | 747 | 645 | 733 | 77.1 | 632 | 638 | 681 | 705 | 684 | 67.2 | 610

08 —t P0O->PI —@ Po->P2 08 —e PO->PI —e PO>P2 0.8 mm GCN GIN m= GMT 08 Random Walk

Accuracy
2
g
Accuracy
°
g

05 06 07 08 09 01 02 03 04 05

(a) Threshold ¢ (b) Noise ratio a
Figure 2: Hyperparameter sensitivity analysis of threshold ¢
and noise ratio a on the PROTEINS datasets.

enforces multi-view prediction consistency, providing a ro-
bust foundation for effective domain adaptation. (2) NeGPR
w/o NRL demonstrates inferior performance compared to
NeGPR. The NRL effectively reduces the negative impact
of noisy labels in the source domain by promoting local
consistency among neighboring nodes. This constraint en-
ables NeGPR to learn noise-resistant representations suit-
able for domain adaptation. (3) NeGPR outperforms NeGPR
w/o NTR, demonstrating that the noise tolerant regulariza-
tion effectively mitigates the impact of noisy pseudo-labels
by preserving reliable supervision from clean samples. This
constraint prevents overfitting and enhances the model’s ro-
bustness and generalization across domains. Additional re-
sults on other datasets are provided in Appendix E.

Sensitivity Analysis

We perform a sensitivity analysis to examine how the key
hyperparameters of NeGPR, namely the pseudo-label con-
fidence threshold ¢ and the noise ratio a, affect its per-
formance. Specifically, ¢ governs the selection of high-
confidence pseudo-labeled target samples, while a deter-
mines the proportion of corrupted labels in the source do-
main. Both parameters play a critical role in balancing su-
pervision quality and model robustness.

Figure 2 illustrates how ¢ and a affect the perfor-
mance of NeGPR on the PROTEINS dataset. We vary
¢ within the range of {0.5,0.6,0.7,0.8,0.9} and a@ in
{0.1, 0.2, 0.3, 0.4,0.5}. From the results, we observe that:
(1) The performance of NeGPR in Figure 2(a) steadily in-
creases as threshold ¢ rises. A higher threshold can effec-
tively filter out pseudo-labels with lower confidence, which
reduces the risk of propagating incorrect information during
model training, enabling the model to learn from more reli-
able supervision signals. Thus, we set the threshold ¢ to 0.9
as default to ensure optimal pseudo-label reliability. (2) Fig-
ure 2(b) illustrates a decreasing accuracy trend with an in-

°
Na
°
N

Accuracy
Accuracy

°
a
o
a

PO->PI P1- SPO PO->P2 P2>P0

(b) Different backbone for EB

P0- SPI P1- Spo Po- >P2 P2- >P0

(a) Different backbone for IB

Figure 3: The performance with different backbones for IB
and EB on the PROTEINS dataset.

creasing noise ratio a. A higher noise ratio introduces more
incorrectly labeled samples into the source domain, thereby
degrading the reliability of supervisory signals during train-
ing. Consequently, this prevents the model from accurately
learning discriminative representations. To maintain a bal-
ance between realistic data conditions and robust perfor-
mance, we set the noise ratio a to 0.3 by default. More re-
sults on other datasets are shown in Appendix E.

Flexible Architecture

To assess the impact of different backbone choices for the
IB and EB branches, we evaluate various message passing
methods in IB, including GCN (Kipf and Welling 2017a),
GAT (Velicékovié et al. 2018), GIN (Xu et al. 2019), and
GMT (Baek, Kang, and Hwang 2021), and adopt several
graph kernel-based methods in EB, such as Graph Sam-
pling (Leskovec and Faloutsos 2006), Random Walk (Kalo-
folias, Welke, and Vreeken 2021), WL (Shervashidze et al.
2011), and PathNN (Michel et al. 2023). As shown in Fig-
ure 3, and consistently observed across other datasets, GMT
and PathNN yield the best performance in most cases. This
can be attributed to their superior representation capacity,
which provides a solid foundation for capturing both seman-
tic and topological features of graphs. These results further
validate our choice of GMT in IB and PathNN in EB, as
they offer complementary strengths that enhance the effec-
tiveness of dual-branch modeling. Their strong performance
also highlights the importance of backbone selection in en-
suring stable adaptation under noisy supervision.

Conclusion

This paper introduces NeGPR, a noise-aware dual-branch
framework for robust GDA under label noise. To tackle
noisy supervision and distributional shifts, NeGPR em-
ploys a dual-branch pretraining strategy: one branch cap-
tures semantic consistency via local message passing, while


the other encodes structural features using a graph kernel
method, enabling the extraction of complementary graph
representations. A nested pseudo-label refinement mecha-
nism progressively aligns source and target domains by al-
ternately using high-confidence predictions from one branch
to supervise the other, enhancing cross-branch consistency
and mitigating domain gaps. Additionally, a noise-aware
regularization term penalizes overconfident or inconsistent
predictions, reducing the impact of noisy labels. Extensive
experiments across diverse datasets and noise settings vali-
date the superior robustness and generalization of NeGPR,
underscoring its promise for reliable graph transfer learning.

References

Baek, J.; Kang, M.; and Hwang, S. J. 2021. Accurate learn-
ing of graph representations with graph multiset pooling.
arXiv preprint arXiv:2102.11533.

Borgwardt, K. M.; and Kriegel, H.-P. 2005. Shortest-path
kernels on graphs. In Fifth IEEE international conference
on data mining (ICDM’05), 8—pp. IEEE.

Cai, R.; Wu, F; Li, Z.; Wei, P.; Yi, L.; and Zhang, K. 2024.
Graph domain adaptation: A generative view. ACM Trans-
actions on Knowledge Discovery from Data, 18(3): 1-24.

Chen, J.; Shah, V.; and Kyrillidis, A. 2020. Negative sam-
pling in semi-supervised learning. In International Confer-
ence on Machine Learning, 1704-1714. PMLR.

Chen, X.; Wang, Y.; Fang, J.; Meng, Z.; and Liang, S. 2023.
Heterogeneous graph contrastive learning with metapath-
based augmentations. IEEE Transactions on Emerging Top-
ics in Computational Intelligence, 8(1): 1003-1014.

Cho, H.; Berger, B.; and Peng, J. 2016. Compact integration
of multi-network topology for functional analysis of genes.
Cell systems, 3(6): 540-548.

Dai, E.; Aggarwal, C.; and Wang, S. 2021. Nrgnn: Learn-
ing a label noise resistant graph neural network on sparsely
and noisily labeled graphs. In Proceedings of the 27th ACM
SIGKDD conference on knowledge discovery & data min-
ing, 227-236.

Dan, J.; Liu, W.; Xie, X.; Yu, H.; Dong, S.; and Tan, Y. 2024.
TFGDA: Exploring topology and feature alignment in semi-
supervised graph domain adaptation through robust cluster-
ing. Proceedings of the Conference on Neural Information
Processing Systems, 37: 50230-50255.

Dobson, P. D.; and Doig, A. J. 2003. Distinguishing enzyme
structures from non-enzymes without alignments. Journal
of molecular biology, 330(4): 771-783.

Feng, L.; Shu, S.; Lin, Z.; Lv, F; Li, L.; and An, B. 2021.
Can cross entropy loss be robust to label noise? In Pro-

ceedings of the International Joint Conference on Artificial
Intelligence, 2206-2212.

Feng, Y.; Zhu, H.; Peng, D.; Peng, X.; and Hu, P. 2023.
Road: Robust unsupervised domain adaptation with noisy
labels. In Proceedings of the ACM International Conference
on Multimedia, 7264-7273.

Ganin, Y.; Ustinova, E.; Ajakan, H.; Germain, P.; Larochelle,
H.; Laviolette, F; March, M.; and Lempitsky, V. 2016.

Domain-adversarial training of neural networks. Journal of
machine learning research, 17(59): 1-35.

Gilmer, J.; Schoenholz, S. S.; Riley, P. F; Vinyals, O.; and
Dahl, G. E. 2017. Neural message passing for quantum
chemistry. In International conference on machine learn-
ing, 1263-1272. Pmlr.

Hamilton, W. L.; Ying, R.; and Leskovec, J. 2017. Inductive
representation learning on large graphs. In Proceedings of
the Conference on Neural Information Processing Systems.

Han, B.; Yao, Q.; Yu, X.; Niu, G.; Xu, M.; Hu, W.; Tsang,
I.; and Sugiyama, M. 2018. Co-teaching: Robust training of
deep neural networks with extremely noisy labels. Advances
in neural information processing systems, 31.

Iscen, A.; Valmadre, J.; Arnab, A.; and Schmid, C. 2022.
Learning with neighbor consistency for noisy labels. 2022
IEEE. In CVF Conference on Computer Vision and Pattern
Recognition (CVPR), 4662-4671.

Kalofolias, J.; Welke, P.; and Vreeken, J. 2021. SUSAN: The
Structural Similarity Random Walk Kernel. In Proceedings
of the SIAM International Conference on Data Mining, 298—
306.

Kazius, J.; McGuire, R.; and Bursi, R. 2005. Derivation
and validation of toxicophores for mutagenicity prediction.
Journal of medicinal chemistry, 48(1): 312-320.

Kipf, T. N.; and Welling, M. 2017a. Semi-supervised clas-
sification with graph convolutional networks. In Proceed-
ings of the International Conference on Learning Represen-
tations.

Kipf, T. N.; and Welling, M. 2017b. Semi-Supervised Clas-
sification with Graph Convolutional Networks. In Proceed-
ings of the International Conference on Machine Learning.

Lee, D.-H.; et al. 2013. Pseudo-label: The simple and effi-
cient semi-supervised learning method for deep neural net-
works. In Workshop on challenges in representation learn-
ing, ICML, volume 3, 896. Atlanta.

Leskovec, J.; and Faloutsos, C. 2006. Sampling from large
graphs. In Proceedings of the International ACM SIGKDD
Conference on Knowledge Discovery & Data Mining, 631-
636.

Li, J.; Socher, R.; and Hoi, S. C. 2020. Dividemix: Learn-
ing with noisy labels as semi-supervised learning. arXiv
preprint arXiv:2002.07394.

Lin, M.; Li, W.; Li, D.; Chen, Y.; Li, G.; and Lu, S. 2023.
Multi-domain generalized graph meta learning. In Pro-
ceedings of the AAAI Conference on Artificial Intelligence,
4479-4487.

Liu, M.; Fang, Z.; Zhang, Z.; Gu, M.; Zhou, S.; Wang, X.;
and Bu, J. 2024a. Rethinking propagation for unsupervised
graph domain adaptation. In Proceedings of the AAAI Con-
ference on Artificial Intelligence, 13963-13971.

Liu, S.; Li, T.; Feng, Y.; Tran, N.; Zhao, H.; Qiu, Q.; and
Li, P. 2023. Structural re-weighting improves graph domain

adaptation. In Proceedings of the International Conference
on Machine Learning, 21778-21793. PMLR.


Liu, S.; Zou, D.; Zhao, H.; and Li, P. 2024b. Pairwise Align-
ment Improves Graph Domain Adaptation. In Proceed-
ings of the International Conference on Machine Learning,

32552-32575. PMLR.

Long, M.; Cao, Y.; Wang, J.; and Jordan, M. 2015. Learn-
ing transferable features with deep adaptation networks.
In International conference on machine learning, 97-105.
PMLR.

Long, M.; Cao, Z.; Wang, J.; and Jordan, M. I. 2018. Condi-
tional adversarial domain adaptation. In Proceedings of the
Conference on Neural Information Processing Systems.
Luo, Y.; Wang, Z.; Chen, Z.; Huang, Z.; and Baktashmot-
lagh, M. 2023. Source-free progressive graph learning for
open-set domain adaptation. [EEE Transactions on Pattern
Analysis and Machine Intelligence, 45(9): 11240-11255.

Michel, G.; Nikolentzos, G.; Lutzeyer, J. F.; and Vazirgian-
nis, M. 2023. Path neural networks: Expressive and accurate
graph neural networks. In Proceedings of the International
Conference on Machine Learning, 24737-24755. PMLR.

Natarajan, N.; Dhillon, I. S.; Ravikumar, P. K.; and Tewari,
A. 2013. Learning with noisy labels. Advances in neural
information processing systems, 26.

Nikolentzos, G.; Siglidis, G.; and Vazirgiannis, M. 2021.
Graph kernels: A survey. Journal of Artificial Intelligence
Research, 72: 943-1027.

Orsini, F.; Frasconi, P.; and De Raedt, L. 2015. Graph in-
variant kernels. In Proceedings of the International Joint
Conference on Artificial Intelligence.

Pei, Z.; Cao, Z.; Long, M.; and Wang, J. 2018. Multi-
adversarial domain adaptation. In Proceedings of the AAAI
conference on artificial intelligence, volume 32.

Platanios, E. A.; Dubey, A.; and Mitchell, T. 2016. Esti-
mating accuracy from unlabeled data: A bayesian approach.
In International Conference on Machine Learning, 1416—
1425. PMLR.

Qian, S.; Ying, H.; Hu, R.; Zhou, J.; Chen, J.; Chen, D. Z.;
and Wu, J. 2023. Robust training of graph neural networks
via noise governance. In Proceedings of the International
ACM Conference on Web Search & Data Mining, 607-615.
Qiao, Z.; Luo, X.; Xiao, M.; Dong, H.; Zhou, Y.; and Xiong,
H. 2023. Semi-supervised domain adaptation in graph trans-

fer learning. In Proceedings of the International Joint Con-
ference on Artificial Intelligence, 2279-2287.

Rizve, M. N.; Duarte, K.; Rawat, Y. S.; and Shah, M. 2021.
In Defense of Pseudo-Labeling: An Uncertainty-Aware
Pseudo-label Selection Framework for Semi-Supervised
Learning. In International Conference on Learning Repre-
sentations.

Shervashidze, N.; Schweitzer, P.; Van Leeuwen, E. J.;
Mehlhormn, K.; and Borgwardt, K. M. 2011. Weisfeiler-
lehman graph kernels. Journal of Machine Learning Re-
search, 12(9).

Stokes, J. M.; Yang, K.; Swanson, K.; Jin, W.; Cubillos-
Ruiz, A.; Donghia, N. M.; MacNair, C. R.; French, S.; Car-
frae, L. A.; Bloom-Ackermann, Z.; et al. 2020. A deep learn-
ing approach to antibiotic discovery. Cell, 180(4): 688-702.

Sutherland, J. J.; O’brien, L. A.; and Weaver, D. F. 2003.
Spline-fitting with a genetic algorithm: A method for devel-
oping classification structure- activity relationships. Jour-
nal of chemical information and computer sciences, 43(6):
1906-1915.

Tzeng, E.; Hoffman, J.; Saenko, K.; and Darrell, T. 2017.
Adversarial discriminative domain adaptation. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition, 7167-7176.

Veli¢kovié, P.; Cucurull, G.; Casanova, A.; Romero, A.; Lio,
P.; and Bengio, Y. 2018. Graph Attention Networks. In Pro-
ceedings of the International Conference on Learning Rep-
resentations.

Veli¢kovié, P.; Cucurull, G.; Casanova, A.; Romero, A.; Lio,
P.; and Bengio, Y. 2018. Graph Attention Networks. Pro-
ceedings of the International Conference on Learning Rep-
resentations.

Wale, N.; Watson, I. A.; and Karypis, G. 2008. Compar-
ison of descriptor spaces for chemical compound retrieval
and classification. Knowledge and Information Systems, 14:
347-375.

Wang, M.; Su, H.; Wang, S.; Wang, S.; Yin, N.; Shen, L.;
Lan, L.; Yang, L.; and Cao, X. 2025. Graph Convolutional
Mixture-of-Experts Learner Network for Long-Tailed Do-
main Generalization. IEEE Transactions on Circuits and
Systems for Video Technology.

Wang, T.; and Isola, P. 2020. Understanding contrastive rep-
resentation learning through alignment and uniformity on
the hypersphere. In Proceedings of the International Con-
ference on Machine Learning, 9929-9939, PMLR.

Wang, Y.; Chang, Y.-Y.; Liu, Y.; Leskovec, J.; and Li, P.
2021. Inductive representation learning in temporal net-
works via causal anonymous walks. arxiv.

Wang, Y.; Liang, V.; Yin, N.; Liu, S.; and Segal, E. 2024a.
SGAC: A Graph Neural Network Framework for Imbal-
anced and Structure-Aware AMP Classification. arXiv
preprint arXiv:2412.16276.

Wang, Y.; Liu, S.; Wang, M.; Liang, S.; and Yin, N. 2024b.
Degree distribution based spiking graph networks for do-
main adaptation. arXiv e-prints, arXiv—2410.

Wang, Y.; and Yang, Y. 2022. Bayesian robust graph con-
trastive learning. arXiv preprint arXiv:2205.14109.

Wang, Y.; Yin, N.; Xiao, M.; Yi, X.; Liu, S.; and Liang, S.
2024c. Dusego: Dual second-order equivariant graph ordi-
nary differential equation. arXiv preprint arXiv:241 1.10000.
Wang, Z.; Sun, D.; Zhou, S.; Wang, H.; Fan, J.; Huang,
L.; and Bu, J. 2024d. NoisyGL: A Comprehensive Bench-
mark for Graph Neural Networks under Label Noise. arXiv
preprint arXiv:2406.04299.

Wei, H.; Feng, L.; Chen, X.; and An, B. 2020. Combating
noisy labels by agreement: A joint training method with co-
regularization. In Proceedings of the IEEE/CVF conference
on computer vision and pattern recognition, 13726-13735.
Wu, M.; Pan, S.; and Zhu, X. 2022. Attraction and repulsion:
Unsupervised domain adaptive graph contrastive learning

network. [EEE Transactions on Emerging Topics in Com-
putational Intelligence, 6(5): 1079-1091.


Xie, Q.; Luong, M.-T.; Hovy, E.; and Le, Q. V. 2020. Self-
training with noisy student improves imagenet classification.
In Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition, 10687-10698.

Xu, G.; Yi, L.; Xu, P.; Li, J.; Pu, R.; Shui, C.; Ling, C.;
McLeod, A. I.; and Wang, B. 2025. Unraveling the Mys-
teries of Label Noise in Source-Free Domain Adaptation:
Theory and Practice. IEEE Transactions on Pattern Analy-
sis and Machine Intelligence.

Xu, K.; Hu, W.; Leskovec, J.; and Jegelka, S. 2018. How
Powerful are Graph Neural Networks? In Proceedings of
the International Conference on Machine Learning.

Xu, K.; Hu, W.; Leskovec, J.; and Jegelka, S. 2019. How
Powerful are Graph Neural Networks? In Proceedings of
the International Conference on Learning Representations.

Yao, T.; Wang, Y.; Zhang, K.; and Liang, S. 2023. Improving
the expressiveness of k-hop message-passing gnns by inject-
ing contextualized substructure information. In Proceedings
of the International ACM SIGKDD Conference on Knowl-
edge Discovery & Data Mining, 3070-3081.

Yin, N.; Feng, F.; Luo, Z.; Zhang, X.; Wang, W.; Luo, X.;
Chen, C.; and Hua, X.-S. 2022a. Dynamic hypergraph con-
volutional network. In 2022 IEEE 38th International Con-
ference on Data Engineering (ICDE), 1621-1634. IEEE.

Yin, N.; Shen, L.; Chen, C.; Hua, X.-S.; and Luo, X. 2024a.
Sport: A subgraph perspective on graph classification with
label noise. ACM Transactions on Knowledge Discovery
from Data, 18(9): 1-20.

Yin, N.; Shen, L.; Li, B.; Wang, M.; Luo, X.; Chen, C.; Luo,
Z.; and Hua, X.-S. 2022b. Deal: An unsupervised domain
adaptive framework for graph-level classification. In Pro-
ceedings of the ACM International Conference on Multime-
dia, 3470-3479.

Yin, N.; Shen, L.; Wang, M.; Lan, L.; Ma, Z.; Chen, C.; Hua,
X.-S.; and Luo, X. 2023a. CoCo: A Coupled Contrastive
Framework for Unsupervised Domain Adaptive Graph Clas-
sification. In Proceedings of the International Conference on
Machine Learning, 40040-40053.

Yin, N.; Shen, L.; Wang, M.; Lan, L.; Ma, Z.; Chen, C.;
Hua, X.-S.; and Luo, X. 2023b. Coco: A coupled contrastive
framework for unsupervised domain adaptive graph classifi-
cation. In Proceedings of the International Conference on
Machine Learning, 40040-40053. PMLR.

Yin, N.; Shen, L.; Wang, M.; Luo, X.; Luo, Z.; and Tao, D.
2023c. Omg: Towards effective graph classification against
label noise. IEEE Transactions on Knowledge and Data En-
gineering, 35(12): 12873-12886.

Yin, N.; Wan, M.; Shen, L.; Patel, H. L.; Li, B.; Gu, B.;
and Xiong, H. 2024b. Continuous spiking graph neural net-
works. arXiv preprint arXiv:2404.01897.

Yin, N.; Wang, M.; Chen, Z.; De Masi, G.; Xiong, H.; and
Gu, B. 2024c. Dynamic spiking graph neural networks. In
Proceedings of the AAAI Conference on Artificial Intelli-
gence, volume 38, 16495-16503.

Yin, N.; Wang, M.; Chen, Z.; Shen, L.; Xiong, H.; Gu, B.;
and Luo, X. 2024d. DREAM: Dual structured exploration

with mixup for open-set graph domain adaption. In Proceed-
ings of the International Conference on Learning Represen-
tations.

Yin, Z.; Feng, Y.; Yan, M.; Song, X.; Peng, D.; and Wang,
X. 2025. RoDA: Robust Domain Alignment for Cross-
Domain Retrieval Against Label Noise. In Proceedings of
the AAAI Conference on Artificial Intelligence, volume 39,
9535-9543.

You, Y.; Chen, T.; Wang, Z.; and Shen, Y. 2022. Bring-
ing your own view: Graph contrastive learning without pre-
fabricated data augmentations. In Proceedings of the Inter-
national ACM Conference on Web Search & Data Mining,
1300-1309.

Yu, X.; Liu, T.; Gong, M.; Zhang, K.; Batmanghelich, K.;
and Tao, D. 2020. Label-noise robust domain adaptation.
In Proceedings of the International Conference on Machine
Learning, 10913-10924. PMLR.

Yu, Y.; Ko, M.; Shin, S.; Kim, K.; and Lee, K. 2024. Cur-
riculum Fine-tuning of Vision Foundation Model for Medi-
cal Image Classification Under Label Noise. Proceedings of
the Conference on Neural Information Processing Systems,
37: 18205-18224.

Yuan, J.; Luo, X.; Qin, Y.; Mao, Z.; Ju, W.; and Zhang, M.
2023a. Alex: Towards effective graph transfer learning with
noisy labels. In Proceedings of the ACM International Con-
ference on Multimedia, 3647-3656.

Yuan, J.; Luo, X.; Qin, Y.; Zhao, Y.; Ju, W.; and Zhang, M.
2023b. Learning on graphs under label noise. In ICASSP
2023-2023 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), 1-5. TEEE.

Zhu, Q.; Jiao, Y.; Ponomareva, N.; Han, J.; and Perozzi, B.
2023. Explaining and Adapting Graph Conditional Shift.
arxiv.

Zhu, Q.; Yang, C.; Xu, Y.; Wang, H.; Zhang, C.; and Han,
J. 2021. Transfer learning of graph neural networks with
ego-graph information maximization. Proceedings of the
Conference on Neural Information Processing Systems, 34:
1766-1779.

Zhu, Y.; Feng, L.; Deng, Z.; Chen, Y.; Amor, R.; and Wit-
brock, M. 2024. Robust node classification on graph data
with graph and label noise. In Proceedings of the AAAI Con-
ference on Artificial Intelligence, volume 38, 17220-17227.


A. Proof of Lemma 1

Lemma 1 Let © denote the parameters vem B'. The gradient of the loss function in Eq. 4 with respect to © is given by
Volk = S> Voz ‘(Pj — Yj +A+B;j),

cteT B

conf

TE

where the regularization gradient g; € R° is defined as

1 T . OPj,c
-J5,4;, with piles = 52

Sj ( = Dj,c(Ock — Pj,k):

Pj, Gj)

Here, 5-x% denotes the Kronecker delta, which equals 1 if c = k and 0 otherwise.

Proof:
LR = LE ine ~~ 7. , log ((o o(2G),0 a(z ZG )))
Te
TE
= Lire ~~ 5 Uj log o( 2G) », log { ( ((o( (zé:), o(zf))) (5)
rz. ter B. mz. Be j j
~~ = LP. + Le.

Due to the pre-training process of dual branches, models are overfitted to the loss £2 ‘, therefore, we simply focus on the

pre?

remaining term £2... Denote pj =o(z ae), q; =o(z ZG), we have:

ate
do Vera: : 557 (6)
ci

cieTB

conf

Vole. =

rest —_ Ty
Tobe

where ln is the loss on the sample Gi of branch B’. Then, we compute the partial derivative of the loss with respect to 22 Gt a

an) .
Dak ~ Dake (—g; log pj — Alog(p;, 43)
y; +r | J, (7)
=Pjy-—yjtra: *Ip Gj,
a (pj,qj)
where J,,, is the Jacobian of the softmax function:
Op },C
[Jp,] k= a a = Dj,clOck — Pj,k)s (8)
oan
where 6-% is the Kronecker delta, equal to 1 if c = k, and 0 otherwise. Define the regularizer gradient vector g; € R®@ as:
T
g7,:= - J, q;. (9)
7" (pj,aj) PP?
The c-th entry of g; can be explicitly expanded as:
D; Cc
Ise
Jie = dj.k — WG,c)Pj,k- (10)
(P5549) »| nes
where c € {1,...,C} denotes the class index; p;,. and q;,, are softmax probabilities from branches B’ and B, respectively.
Substituting Eq. (7) into Eq. (6), we obtain the final vee
VoLrest = 2 Vozg: «(pj — Gj + A+ 83), (11)

\TBel 7, te7B
Gy € Teont

where g; is defined as in Eq. (10).


B. Complexity Analysis

The overall time complexity of the proposed NeGPR framework is determined by two main stages: noise-resilient pre-training
and nested pseudo-label refinement. In the pre-training phase, the Implicit Branch (IB) incurs a complexity of O(L - ({V| +

|E|) -

d,), while the Explicit Branch (EB) has a complexity of O(|V| - ({V| + |E|)) for shortest-path computation, along with

an additional O(n? - d,) for semantic neighbor search, where d, is the embedding dimension and L represents the number of
GNN layers. During the refinement stage, the forward pass over n; target graphs incurs a cost of O(n; - L- (\V| + |E|) -d,-T).
The total time complexity of NeGPR is: O(n, - (ZL: (|V| + |E|)-dg +|V|-(V| + |E])) +2 -d,) + O(ne- L- (\V| + El) -d,-T).

C. Dataset

Table 4: Statistics of the experimental datasets.

Datasets Graphs Avg. Nodes Avg. Edges Classes
NCI1 4,110 29.87 32.30 2
MUTAGENICITY = 4,337 30.32 30.77 2
FRANKENSTEIN — 4,337 16.9 17.88 2
PROTEINS 1,113 39.1 72.8 2
DD 1,178 284.32 715.66 2
COX2 467 41.22 43.45 2
COX2_MD 303 26.28 335.12 2
BZR 405 35.75 38.36 2
BZR_MD 306 21.30 225.06 2

Dataset Description

We conduct extensive experiments on four public benchmark graph datasets from TUDataset. The dataset statistics can be found
in Table 4, and their details are shown as follows:

¢ For structure-based domain shifts:

PROTEINS. The PROTEINS dataset (Dobson and Doig 2003) contains 1,113 protein graphs. Each graph is labeled to
indicate whether the corresponding protein is an enzyme. Nodes represent amino acids, and edges are constructed between
amino acids within 6 A along the sequence. We divide the PROTEINS dataset into four subsets, PO, P1, P2, and P3, based
on edge density, node density, and graph flux, which exhibit significant domain shifts.

NCI1. The NCI1 (Wale, Watson, and Karypis 2008) dataset consists of 4,100 molecular graphs, with atoms as nodes and
chemical bonds as edges. Each graph is labeled based on its ability to inhibit cancer cell growth. Following the PROTEINS
dataset, we divide the NCI1 dataset into four subsets, NO, N1, N2, and N3, based on edge density, node density, and graph
flux.

FRANKENSTEIN. The FRANKENSTEIN (Orsini, Frasconi, and De Raedt 2015) dataset comprises 4,337 molecular
graphs, with atoms as nodes and chemical bonds as edges. Each graph is labeled according to the molecule’s biological
activity. Following the PROTEINS dataset, we divide the FRANKENSTEIN dataset into four subsets, FO, Fl, F2, and F3,
based on edge density, node density, and graph flux.

MUTAGENICITY. The MUTAGENICITY (Kazius, McGuire, and Bursi 2005) dataset includes 4,337 molecular graphs,
where atoms serve as nodes and chemical bonds as edges. Labels indicate whether a compound is mutagenic, contributing
to research in toxicology and chemical risk assessment. Following the PROTEINS dataset, we divide the MUTAGENIC-
ITY dataset into four subsets, MO, M1, M2, and M3, based on edge density, node density, and graph flux.

¢ For feature-based domain shifts:

DD. The DD dataset (Dobson and Doig 2003) contains 1,178 graphs representing protein structures, where nodes rep-
resent amino acids and edges capture spatial or chemical proximity. DD graphs are larger and denser than PROTEINS
graphs, introducing structural variations while maintaining similar label semantics.

COX2. The COX2 dataset (Sutherland, O’brien, and Weaver 2003) contains 467 molecular graphs, while COX2-MD
includes 303 modified molecular graphs. In both datasets, nodes represent atoms and edges correspond to chemical bonds.
COX2_MD introduces structural variations to COX2 while maintaining semantic consistency, making them suitable for
evaluating model robustness under domain shifts.

BZR. The BZR dataset (Sutherland, O’brien, and Weaver 2003) consists of 405 molecular graphs. The BZR_MD dataset
contains 306 graphs with modified structures derived from BZR. Nodes correspond to atoms, and edges represent chemical
bonds. BZR_MD introduces structural variations to simulate domain shifts while maintaining consistent label semantics.


Data processing

In our implementation, we first process the raw graph-structured data, where each instance comprises an adjacency matrix,
node features, and a graph-level label. Then, node representations are generated using available information, such as labels,
attributes, or structural statistics, to ensure consistency across graphs. Furthermore, we incorporate path-based features and
subgraph samples obtained through topology-aware and random sampling strategies to enhance structural representation. These
components are integrated into a unified representation that captures global topology and local substructure information.

D. Baselines

In this part, we introduce the details of the compared baselines as follows:

Graph kernel method. We compare our NeGPR with two graph kernel methods:

— WL: The Weisfeiler-Lehman (WL) subtree method (Shervashidze et al. 2011) iteratively refines node labels by hashing
the concatenation of each node’s current label and the sorted multiset of its neighbors’ labels. This process enables efficient
and expressive encoding of hierarchical structural features.

— PathNN: Path Neural Networks (PathNN) (Michel et al. 2023) enhance expressiveness by explicitly modeling paths
between nodes. They aggregate path-based features through attention mechanisms, capturing higher-order structural de-
pendencies beyond immediate neighbors while preserving permutation invariance and computational efficiency.

Graph neural networks. We compare our NeGPR with four general graph neural networks:

— GCN: Graph Convolutional Networks (GCN) (Kipf and Welling 2017b) update node representations by aggregating
and transforming features from immediate neighbors. They employ a normalized adjacency matrix to ensure numerical
stability and preserve local graph structure during message passing.

— GIN: Graph Isomorphism Networks (GIN) (Xu et al. 2018) aggregate features from neighboring nodes using a sum op-
eration, followed by a multi-layer perceptron. This design enables maximally expressive representations while mitigating
over-smoothing through injective aggregation functions.

— GAT: Graph Attention Networks (GAT) (Veliékovié et al. 2018) compute node representations by assigning learnable
attention weights to neighboring nodes through self-attention mechanisms. This allows for adaptive, weighted feature
aggregation without relying on predefined graph structures or normalization constraints.

— GMT: Graph Multiset Transformer (GMT) (Baek, Kang, and Hwang 2021) employs attention-based pooling with learn-
able queries to aggregate node features into graph-level representations. It decouples feature selection from structural
bias, enabling flexible and expressive global information extraction.

Label denoising methods. We compare our NeGPR with five label denoising methods:

— Co-teaching: Co-teaching (Han et al. 2018) trains two networks simultaneously, where each selects small-loss samples
to teach the other, effectively filtering out noisy labels. This mutual-update strategy dynamically adjusts sample selection,
enhancing robustness against severe label noise.

— RTGNN: RTGNN (Qian et al. 2023) introduces a noise governance framework for graph neural networks by identify-
ing and mitigating noisy nodes through confidence estimation and adaptive neighbor selection. It further incorporates
consistency regularization to ensure stable representation learning under noisy supervision.

-— Taylor-CE: Taylor-CE (Feng et al. 2021) enhances the robustness of cross-entropy loss to label noise by approximating
it with a Taylor series expansion, which attenuates the influence of mislabeled samples through bounded gradients and
smoother optimization dynamics.

- OMG: OMG (Yin et al. 2023c) mitigates label noise in graph classification by jointly optimizing graph embeddings and
label reliability. It employs an online sample reweighting mechanism that dynamically adjusts the training focus based on
prediction confidence and noise estimation.

— SPORT: SPORT (Yin et al. 2024a) addresses label noise by modeling graph classification from a subgraph perspec-
tive, identifying reliable substructures through contrastive learning and sample selection. These substructures are then
integrated using a noise-tolerant voting mechanism to enhance representation fidelity.

Graph domain adaptation methods. We compare our NeGPR with six graph domain adaptation methods:

— DEAL: DEAL (Yin et al. 2022b) is an unsupervised domain adaptation framework that aligns source and target domains
at both the feature and prediction levels using adversarial learning. It further enhances cross-domain generalization by
iteratively refining pseudo-labels through entropy minimization and consistency regularization.

— CoCo: CoCo (Yin et al. 2023b) introduces a coupled contrastive framework that simultaneously aligns instance-level
and class-level representations across domains to capture both fine-grained and semantic-level consistency. It leverages
contrastive objectives to enhance feature discrimination and cross-domain coherence.


-— SGDA: SGDA (Qiao et al. 2023) integrates semi-supervised learning with domain adaptation by leveraging limited la-
beled target data to guide feature alignment between domains. It employs consistency regularization and entropy mini-
mization to enhance representation transfer and reduce domain shift.

— A2GNN: A2GNN (Liu et al. 2024a) reexamines feature propagation in graph domain adaptation by introducing a
structure-aware propagation strategy that mitigates noise amplification. It further incorporates domain-specific normal-
ization to enhance stability and alignment during unsupervised adaptation.

— StruRW: StruRW (Liu et al. 2023) introduces a structural re-weighting mechanism that dynamically adjusts the impor-
tance of nodes and edges based on their domain relevance. It enhances feature alignment by emphasizing transferable
structures while suppressing domain-specific noise.

— PA-BOTH: PA-BOTH (Liu et al. 2024b) leverages pairwise alignment to explicitly match semantically similar node pairs
across domains, enhancing structural and feature-level consistency. It further refines domain adaptation by integrating
alignment signals into the representation learning process.

* Label denoising domain adaptation methods. We compare our NeGPR with two label denoising domain adaptation meth-
ods:

— ALEX: ALEX (Yuan et al. 2023a) proposes a noise-robust graph transfer learning framework that addresses label noise
in the source domain through adaptive label correction and structure-aware contrastive learning. It jointly refines pseudo-
labels and aligns domain-invariant representations to improve cross-domain generalization under noisy supervision.

— ROAD: ROAD (Feng et al. 2023) introduces a robust Unsupervised Domain Adaptation (UDA) framework that combats
source label noise and domain shift by combining source sample weighting, confident target regularization, and adversar-
ial alignment. It enhances model generalization by jointly filtering noisy labels and promoting cross-domain consistency.

For GCN, GIN, GAT, and GMT, we implement the models using PyTorch Geometric!. For the other baseline methods, we
utilize the official source code released by the respective authors. All models are trained using the Adam optimizer with a
learning rate of 10~4, a hidden embedding dimension of 256, a weight decay of 10~!?, and GNN layers of 4.

E. More experimental results
More Performance Comparison

In this part, we provide additional results for our proposed method NeGPR compared with all baseline models across various
datasets, as illustrated in Table 8-18. These results consistently show that NeGPR outperforms the baselines in most cases,
validating the superiority of our proposed method.

More Ablation study

To validate the effectiveness of the different components in NeGPR, we conduct more experiments with four variants on the
NCI1, FRANKENSTEIN and MUTAGENICITY datasets, i.e., NeGPR w/o IB, NeGPR w/o EB, NeGPR w/o NRL, and NeGPR
w/o NTR. The results are shown in Table 5 , 6 and 7. From the results, we have similar observations as summarized in Section
4.3.

More Sensitivity Analysis

In this part, we provide additional results about the flexible architecturesensitivity analysis of the proposed NeGPR with respect
to the impact of its hyperparameters: threshold ¢ and noise ratio a on the NCI1, FRANKENSTEIN, and MUTAGENICITY
datasets. The results are illustrated in Figure 4 and 5, where we observe trends similar to those discussed in Section 4.4.

More Flexible Architecture

In this part, we provide additional results about the flexible architecture of the proposed NeGPR on the NCI1, FRANKEN-
STEIN, and MUTAGENICITY datasets. The results are illustrated in Figure 6 and 7, where we observe trends similar to those
discussed in Section 4.5.

“https://www.pyg.org/


0.75 0.75 0.70

—*— NO->NI —® NO>N2 —* M0->MI1 —@ M0->M2 —*— FO>FI —@- FO->F2
-®- NINO -@- N2->NO -®- MI1->M0 = -@- M2->M0 -®- FI>FO  -@- F2->F0
a a a
i”) i”) 4 i”) 4
s 4 s 0.70 ee Fs 0.65
BS 0.65 7 @---555 e------ , ol ~~ 5 5
3 3 0.65 ~—— rt 3 0.60
< - < e------ ee----- -—— Te ° < .
--- oe
@------ @------ -
0.55 “+ T T T T 0.60 “+ T T T T 0.55 "+ T T T T
0.5 0.6 0.7 0.8 0.9 0.5 0.6 0.7 0.8 0.9 0.5 0.6 0.7 0.8 0.9
(a) NCI (b) MUTAGENICITY (c) FRANKENSTEIN

Figure 4: Hyperparameter sensitivity analysis of threshold ¢ on the NCI1, MUTAGENICITY, and FRANKENSTEIN datasets.

0.75 0.75 0.70
—*— NONI —@- NO->N2 —*t— M0->MI1 —@ M0->M2 —e— FO>FI —@ FO->F2
—w- NINO -@- N2->NO | -*- M1->MO -@- M2->M0O —w- FIl>FO -@- F2->F0
a a a
s s 0.70 4 s 0.65 4
Ss 0.655 5 5
3 3 0.65 3 0.60
< <0 <0
0.55 “+ ‘ ‘ T ‘ 0.60 ——+ ‘ ‘ T T 0.55 “+ ‘ ‘ T ‘
0.1 0.2 03 0.4 0.5 0.1 0.2 03 0.4 0.5 0.1 0.2 03 0.4 0.5
(a) NCI (b) MUTAGENICITY (c) FRANKENSTEIN

Figure 5: Hyperparameter sensitivity analysis of noise ratio a on the NCI1, MUTAGENICITY, and FRANKENSTEIN datasets.

0.7 0.8 0.7

lm GCN GAT GIN. El GMT lm GCN GAT GIN. El GMT lm GCN GAT GIN. El GMT

a > 0.74 >

FS FS s

5 0.64 5 5 0.64

3 3 3

0.5 T T t T 0.5 T T t T 0.5 T T t T
NO->N1_ NI->NO NO->N2 N2->N0 MO0->M1 M1->M0 M0->M2 M2->M0 FO->F1  F1->FO = FO0->F2 ~~ F2->F0
(a) NCI (b) MUTAGENICITY (c) FRANKENSTEIN

Figure 6: The performance with different backbones for IB on the NCI1, MUTAGENICITY, and FRANKENSTEIN datasets.

0.7 0.8 0.7

=m WL Random Walk =m WL Random Walk =m WL Random Walk
Graph Sampling lim PathNN Graph Sampling lim PathNN Graph Sampling lim PathNN

NO->NI1_ NI->NO NO->N2  N2->N0 M0->M1 MI1->M0 M0->M2 M2->M0 FO->F1  FI->FO = FO->F2 ~—-F2->F0

(a) NCI (b) MUTAGENICITY (c) FRANKENSTEIN

o
Q
L

Accuracy
°
an
L
Accuracy
Accuracy
°
an
L

So
a
L

in

0.

in
in

Figure 7: The performance with different backbones for EB on the NCI1, MUTAGENICITY, and FRANKENSTEIN datasets.

Table 5: The results of ablation studies on the NCI1 dataset (source — target). Bold results indicate the best performance per
column.

Methods | NONI | NI-NO | NO-+N2 | N2NO | NO-+N3 | N3-+NO | NI->N2 | N2>N1 | NI>N3 | N3-3NI | N2N3 | N3>N2
NeGPR w/o IB 51.2 51.3 49.2 49.9 49.7 49.5 49.3 50.2 52.1 50.0 53.5 50.3
NeGPR w/o EB 50.1 50.8 50.6 50.8 51.5 50.7 49.5 50.1 50.1 49.9 51.6 50.7
NeGPR w/o NRL | 58.0 58.8 60.1 60.0 59.0 51.8 59.2 60.0 59.1 58.2 57.5 59.1
NeGPR w/o NTR | 58.5 60.8 61.1 62.9 58.3 51.2 59.6 57.5 59.8 59.2 58.8 58.7

NeGPR | 60.7 | 619 | 614 | 668 | 605 | 523 | 602 | 628 | 615 | 606 | 634 | 59.6


Table 6: The results of ablation studies on the FRANKENSTEIN dataset (source — target). Bold results indicate the best
performance.

Methods | FOF | FIFO | FO-F2 | F2-F0 | FO>F3 | F3-+F0 | FI->F2 | F2>F1 | FI-F3 | F3-FI | F2>F3 | F3-+F2

NeGPR w/o IB 51.4 49.3 49.5 50.3 49.5 49.7 49.7 50.7 50.4 50.5 50.4 50.7
NeGPR w/o EB 51.4 50.2 48.6 49.9 45.9 48.8 50.6 49.3 49.4 50.2 48.9 50.8
NeGPR w/o NRL 60.4 58.3 58.7 58.2 67.3 58.0 58.8 56.3 68.9 56.0 72.7 58.6
NeGPR w/o NTR 60.3 59.1 59.3 59.3 66.9 58.8 60.1 57.8 67.9 58.9 73.3 57.7

NeGPR | 63.9 | 604 | 609 | 634 | 682 | 599 | 606 | 597 | 721 | 596 | 74.7 | 59.4

Table 7: The results of ablation studies on the MUTAGENICITY dataset (source — target). Bold results indicate the best
performance.

Methods | MO>MI1 | MIMO | MO>M2 | M2>MO0 | MO>M3 | M33MO0 | M1>M2 | M2>MI | MI>M3 | M3>M1 | M23M3 | M33M2
NeGPR w/o IB 52.7 50.3 50.8 48.5 50.5 50.9 51.2 50.7 50.5 49.5 48.8 49.4
NeGPR w/o EB 52.7 51.0 51.5 50.8 44.3 49.0 52.6 50.1 51.8 48.7 46.0 49.8
NeGPR w/o NRL | 67.5 64.9 62.5 62.9 57.7 64.2 62.6 69.1 62.2 61.4 57.1 63.3
NeGPR w/o NTR | 66.4 64.8 60.6 62.2 58.2 65.1 63.5 70.8 63.9 61.7 58.5 614
NeGPR | 701 | 656 | 66.7 | 639 59.7 | 659 | 658 | 723 | 642 | 636 | 591 | 65.6

Table 8: The classification results (in %) on the PROTEINS dataset under edge density domain shift (source — target). PO, P1,
P2, and P3 denote the sub-datasets partitioned with node density. Bold results indicate the best performance.

Methods PO-—P1 | PI-—PO | PO--P2 | P2—PO | PO--P3 | P3-—PO | PI-—P2 | P2—Pl | PI-—P3 | P3-—PI | P2—P3 | P3-P2

WL 68.141.7 | 31.2409 | 54.3415 | 66.7423 | 24.841.2 | 21.941.1 | 50.242.0 | 42.8415 | 34.041.1 | 61.0408 | 33.6409 | 44.1422
PathNN 68.3411 | 73.041.2 | 55.4408 | 38.541.0 | 25.7409 | 22.941.1 | 40.1407 | 64.0414 | 34.741.2 | 27.941.3 | 67.3409 | 46.941.0
GCN 67.641.2 | 73.7411 | 56.2408 | 71.842.0 | 24.141.1 | 22.8407 | 52.7413 | 64.3415 | 27.7412 | 46.040.9 | 30.741.0 | 47.3414
GIN 62.7413 | 49.1408 | 50.941.2 | 49.7409 | 25.141.1 | 60.340.7 | 45.641.0 | 46.1412 | 66.441.0 | 44.6414 | 43.1406 | 48.8+0.9
GAT 63.041.2 | 68.5+1.0 | 50.5409 | 65.9421 | 64.841.3 | 17.7408 | 49.341.0 | 63.1415 | 46.2412 | 25.8411 | 33.4407 | 49.3414
GMT 54.9+1.5 | 51.4414 | 53.541.2 | 51.9414 | 43.1412 | 46.1410 | 51.4414 | 46.5406 | 47.8419 | 47.8407 | 54.3424 | 49.0414

Co-teaching | 67.7413 | 69.5409 | 54.641.0 | 69.1421 | 24.9408 | 25.9407 | 49.6411 | 61.7415 | 39.2+1.0 | 47.8412 | 43.3409 | 46.7410
Taylor-CE 66.141.2 | 66.0409 | 49.6411 | 54.1408 | 28.2413 | 57.741.0 | 50.9407 | 42.3412 | 70.0406 | 40.2+0.8 | 40.1+1.0 | 42.3409
RTGNN 63.3412 | 76.0+1.1 | 61.5408 | 67.4413 | 26.3409 | 20.3407 | 55.54+1.0 | 67.7414 | 24.7+1.0 | 49.1412 | 34.541.1 | 44.3408
OMG 65.2+1.0 | 72.5+1.1 | 47.4409 | 63.541.2 | 68.341.0 | 22.7407 | 46.6413 | 59.641.5 | 52.8+1.2 | 21.5408 | 35.3409 | 43.9411

SPORT 61.041. 65.0+1.2 | 48.8+0.9 | 68.8+1.0 | 54.9413 | 52.141.0 | 55.6408 | 64.6414 | 51.9411 | 26.041.2 | 34.541.0 | 42.641.1

CoCo 67.3412 | 51.1409 | 55.541.0 | 64.7413 | 71.741.1 | 26.1407 | 51.941.0 | 55.441. 37.041.2 | 56.640.8 | 38.541.0 | 44.841.3
DEAL 66.241. 72.3+1.0 | 54.2+0.9 | 71.9413 | 35.241.0 | 58.5408 | 50.641.2 | 65.5407 | 44.541.0 | 67.441.2 | 64.5409 | 47.441.1
SGDA 67.4412 | 58.741.1 | 58.3409 | 73.0414 | 38.8408 | 32.441.0 | 48.1412 | 49.4409 | 39.941.0 | 59.2411 | 40.8407 | 46.7+41.0
A2GNN 60.6+1.0 | 66.341.2 | 54.0409 | 68.6413 | 59.941.1 | 53.9408 | 44.041.0 | 62.9412 | 43.5407 | 36.641.0 | 46.441.1 | 54.3409
StruRW 62.441. 73.041.2 | 60.2+0.9 | 71.6413 | 40.5408 | 34.8+1.0 | 49.541.2 | 66.5414 | 37.141.0 | 61.741.1 | 41.2407 | 46.8+41.0
PA-BOTH 64.941. 73.041.2 | 57.7409 | 68.9413 | 36.3+1.0 | 55.0+1.0 | 53.9408 | 67.141. 42.9+1.0 | 68.3+0.9 | 62.8+1.0 | 45.3412
ROAD 64.443.4 | 83.542.0 | 57.741.8 | 70.2421 | 44.043.0 | 43.442.2 | 56.9426 | 62.443. 59.0423 | 62.141.7 | 60.642.0 | 57.6+1.7
ALEX 70.7433 | 73.8+2.1 | 60.5424 | 73.8428 | 69.043.3 | 62.443.0 | 58.0425 | 64.343.2 | 69.0428 | 67.1426 | 68.7422 | 60.2427

NeGPR 70.341.9 | 77.242.1 | 61.6415 | 76.9410 | 76.6+2.2 | 66.742.0 | 60.1412 | 70.5423 | 72.3414 | 69.342.7 | 70.5414 | 62.3428


Table 9: The classification results on the PROTEINS dataset under node density domain shift (source — target). PO, P1, P2 and
P3 denote the sub-datasets partitioned with graph flux density. Bold results indicate the best performance.

Methods PO—P1 | PI1-—PO | PO--P2 | P2—PO | PO--P3 | P3-—PO | PI-—P2 | P2-—Pl | PI-P3 | P3-PI | P2—P3 | P3-P2

WL 67.2+2.0 | 33.243.1 | 56.5423 | 69.4419 | 26.5424 | 20.942.0 | 51.2425 | 44.1423 | 32.8420 | 60.5421 | 34.1420 | 41.8424
PathNN 69.2+2.1 | 71.2+2.2 | 55.942.0 | 37.7421 | 26.042.0 | 21.842.2 | 41.1423 | 62.842.0 | 33.2421 | 28.242.0 | 66.5423 | 47.0421
GCN 68.0+2.1 | 72.0+2.0 | 56.542.2 | 71.7423 | 25.4421 | 24.142.0 | 54.0423 | 63.642.2 | 28.0421 | 46.042.0 | 31.2420 | 47.4421
GIN 61.7423 | 50.2+2.4 | 52.1422 | 49.9421 | 43.242.0 | 56.5423 | 44.7+2. 47.0+2.2 | 58.6421 | 43.142.0 | 42.8421 | 49.2+2.2
GAT 63.242.2 | 67.4421 | 51.0423 | 67.1422 | 64.0423 | 19.142.0 | 50.342.2 | 62.3423 | 45.9421 | 26.2421 | 32.5422 | 48.6423
GMT 56.24+1.7 | 51.2416 | 51.4407 | 53.0413 | 43.041.0 | 48.541.1 | 51.6419 | 52.2416 | 47.6414 | 49.041.2 | 46.1409 | 47.941.8
Co-teaching | 66.9423 | 69.5421 | 54.542.2 | 68.9421 | 25.2420 | 26.2423 | 50.1421 | 62.0422 | 39.342.0 | 47.0421 | 43.5420 | 46.1122
Taylor-CE 66.242.1 | 67.042.0 | 48.642.2 | 53.2423 | 28.4421 | 58.042.0 | 51.2421 | 42.1423 | 60.042.0 | 40.2421 | 39.742.0 | 41.642.2
RTGNN 62.542.2 | 76.8423 | 60.54+2.1 | 68.042.2 | 26.342.0 | 19.8421 | 55.4423 | 66.742.0 | 24.142.0 | 49.342.2 | 34.2421 | 44.3420
OMG 65.2+2.1 | 72.5+2.2 | 47.4421 | 63.6423 | 68.442.0 | 22.6+2.0 | 46.8+2. 59.642.2 | 52.8+2.0 | 21.542.0 | 35.3421 | 43.9+2.0
SPORT 61.0+2.1 | 65.7+2.0 | 48.8+2.2 | 69.4423 | 55.1421 | 52.0421 | 55.6+2. 64.5+2.0 | 51.9422 | 25.6421 | 34.342.0 | 42.5+2.2
CoCo 67.2+2.0 | 51.2+2.1 | 55.5+2.2 | 64.742.0 | 71.7423 | 26.1421 | 51.9+2. 55.3+42.1 | 37.042.0 | 56.542.2 | 38.542.1 | 44.7+2.0
DEAL 65.9418 | 72.0413 | 53.9429 | 71.6418 | 35.0414 | 58.241.7 | 50.3425 | 65.841.8 | 44.241.6 | 67.7423 | 64.341.1 | 47.2425
SGDA 67.2413 | 59.0+2.5 | 58.042.2 | 72.741.7 | 38.6409 | 32.7413 | 47.9419 | 49.1427 | 39.6415 | 58.943.1 | 40.5424 | 46.441.2
A2GNN 60.3413 | 66.041.9 | 53.741.2 | 68.3424 | 59.7418 | 53.641.7 | 43.7406 | 62.6419 | 43.2414 | 36.3423 | 46.1415 | 54.143.4
StruRW 62.140.7 | 73.3415 | 59.9414 | 71.3409 | 40.2414 | 34.5425 | 49.2418 | 66.2419 | 36.843.5 | 61.441.7 | 40.941.2 | 46.541.8
PA-BOTH 64.640.5 | 73.34+1.1 | 57.4436 | 68.743.9 | 36.042.7 | 54.843.1 | 53.6433 | 66.8415 | 42.6414 | 68.041.7 | 62.5412 | 45.041.8
ROAD 64.4+2.4 | 68.0+2.2 | 59.4426 | 70.341.7 | 54.442.0 | 57.541.8 | 59.1423 | 64.6427 | 54.442.0 | 64.543.1 | 54.9429 | 57.1423
ALEX 73.642.2 | 73.7423 | 61.543.2 | 73.6428 | 68.7414 | 63.742.9 | 62.2415 | 68.5422 | 61.1426 | 66.9423 | 67.141.6 | 60.5424

NeGPR 72.8424 | 77.7415 | 63.341.7 | 75.1419 | 77.542.7 | 66.1416 | 61.941.8 | 70.9414 | 63.9419 | 73.142.7 | 67.8415 | 61.9423

Table 10: The classification results (in %) on the NCI1 dataset under graph flux density domain shift (source — target). NO,
N1, N2 and N3 denote the sub-datasets partitioned with graph flux. Bold results indicate the best performance.

Methods NO—N1 | NI-NO | NO-N2 | N2—N0 | NO-N3 | N3-NO | NI-N2 | N2-NI1 | NI-N3 | N3-N1 | N2N3 | N3-N2

WL 45.3412 | 55.2430 | 44.3424 | 35.6418 | 33.5409 | 30.6422 | 49.2415 | 53.2+20 | 63.3416 | 51.2431 | 47.5410 | 47.9423
PathNN 53.3415 | 42.1413 | 54.0408 | 64.2419 | 42.8422 | 29.3411 | 50.8420 | 55.7409 | 60.1421 | 48.3423 | 58.9410 | 51.5417
GCN 45.7422 | 63.4415 | 44.8420 | 28.3410 | 34.4412 | 30.4417 | 50.5+09 | 46.3421 | 42.0+1.6 | 45.3420 | 55.1415 | 45.1418
GIN 45.7424 | 63.0421 | 47.2416 | 34.2420 | 57.041.0 | 28.3417 | 46.2409 | 47.6420 | 59.3415 | 49.1423 | 60.8419 | 49.7+08
GAT 45.2419 | 29.1413 | 44.441.7 | 62.8421 | 33.0410 | 31.1415 | 46.1422 | 48.2+10 | 57.4418 | 50.2+24 | 54.9409 | 47.3423
GMT 48.4+08 | 49.841.7 | 49.0415 | 49.7409 | 50.2+1.0 | 48.9426 | 49.7424 | 50.5423 | 48.7411 | 50.4+1.0 | 48.7413 | 49.8416

Co-teaching | 48.9422 | 51.1419 | 48.3415 | 62.4418 | 31.8411 | 29.3410 | 45.5423 | 47.2409 | 44.8417 | 40.9415 | 57.0420 | 46.5412
Taylor-CE 56.1423 | 56.4418 | 45.4417 | 51.0421 | 50.1415 | 28.4410 | 45.2419 | 55.1410 | 60.8414 | 46.8420 | 56.0412 | 53.0+23

RTGNN 40.6415 | 60.1421 | 47.9418 | 31.7409 | 38.1413 | 27.7411 | 51.7420 | 53.5413 | 44.3416 | 51.0415 | 59.2+08 | 42.6419
OMG 51.6420 | 33.8413 | 49.2415 | 65.5422 | 35.5411 | 27.7410 | 50.4420 | 51.8411 | 54.1413 | 47.2415 | 58.7408 | 41.3412
SPORT 52.2423 | 44.9417 | 50.8412 | 57.6418 | 52.3415 | 28.0410 | 50.7419 | 51.2413 | 50.0415 | 53.0411 | 53.4412 | 47.1410
CoCo 52.2417 | 56.7418 | 47.7415 | 42.3410 | 35.7412 | 30.5410 | 48.2414 | 55.9411 | 53.3412 | 53.5415 | 56.1410 | 49.6412
DEAL 58.0418 | 53.8413 | 56.8414 | 63.7415 | 48.3410 | 28.9411 | 50.6413 | 59.2412 | 55.6410 | 48.1414 | 52.5410 | 49.5412
SGDA 52.5+16 | 59.6413 | 48.2414 | 48.8415 | 41.1410 | 27.8410 | 47.3412 | 49.0412 | 53.6413 | 51.1415 | 49.4411 | 44.0412
A2GNN 55.4415 | 49.8412 | 46.3411 | 58.7413 | 48.2+10 | 24.7410 | 43.5410 | 53.0412 | 51.5410 | 47.1413 | 51.2411 | 50.2412
StruRW 48.6414 | 58.8413 | 48.5412 | 52.4410 | 46.041. | 25.341.0 | 46.1413 | 55.5412 | 45.9+10 | 44.9412 | 53.2411 | 46.2410
PA-BOTH 58.4415 | 48.8412 | 52.8413 | 59.6412 | 50.2411 | 28.3410 | 51.9411 | 53.6414 | 60.2410 | 54.1413 | 51.1410 | 51.5412
ROAD 55.2423 | 57.8434 | 53.7424 | 53.0423 | 57.4422 | 50.1428 | 54.5425 | 56.2424 | 58.1422 | 51.9424 | 59.4430 | 56.5429
ALEX 57.7423 | 59.0428 | 57.1421 | 59.4423 | 61.1421 | 57.4415 | 57.2427 | 55.8418 | 58.6423 | 56.0422 | 60.4416 | 58.1421

NeGPR 60.7+2.7 | 61.9418 | 61.4422 | 66.8415 | 60.5412 | 52.3419 | 60.6428 | 62.8422 | 61.5425 | 60.6427 | 63.4413 | 59.6425



Table 11: The classification results (in %) on the NCI1 dataset dataset under edge density domain shift (source — target). NO,
N1, N2 and N3 denote the sub-datasets partitioned with edge density. Bold results indicate the best performance.

Methods NO—N1 | NI-NO | NO-N2 | N2—NO0 | NO-N3 | N3-NO | NI-N2 | N2-NI1 | NI-N3 | N3-N1 | N2>N3 | N3-N2

WL 46.7+07 | 56.1418 | 45.2416 | 34.4414 | 33.3426 | 29.2415 | 48.4437 | 52.7414 | 61.7419 | 50.8+0.7 | 46.8423 | 47.8425
PathNN 52.9+22 | 41.4437 | 53.543. | 63.7418 | 43.5415 | 30.1419 | 51.4426 | 55.0423 | 59.5418 | 47.6412 | 59.5414 | 52.1417
GCN 46.1428 | 64.9414 | 45.0417 | 27.9418 | 33.9413 | 29.7419 | 49.9408 | 47.1416 | 41.6419 | 44.8435 | 56.4432 | 44.5437
GIN 46.8421 | 64.4425 | 46.8422 | 33.6427 | 56.4413 | 29.7413 | 45.6417 | 47.3412 | 60.6+08 | 49.9417 | 60.1413 | 50.6+1.5
GAT 46.3419 | 30.6424 | 45.1423 | 63.4428 | 33.6425 | 29.8427 | 46.3419 | 47.5410 | 56.9414 | 49.5413 | 55.5417 | 46.8419
GMT 50.1412 | 49.2+08 | 49.4413 | 50.2408 | 47.1414 | 50.3406 | 48.9413 | 49.8416 | 53.8417 | 51.5415 | 53.0416 | 49.9410
Co-teaching | 49.4422 | 52.0418 | 48.1409 | 61.8415 | 32.1417 | 28.7425 | 46.0424 | 48.7413 | 45.3417 | 41.4419 | 57.5424 | 45.9416
Taylor-CE 55.6408 | 57.2407 | 44.8+05 | 51.5409 | 49.3412 | 29.0414 | 45.8+19 | 54.7418 | 60.1413 | 46.3417 | 55.4412 | 52.8428
RTGNN 41.3413 | 61.4417 | 48.2412 | 31.4419 | 38.9418 | 27.3414 | 52.2417 | 53.0415 | 43.8419 | 50.8413 | 58.5427 | 42.1418
OMG S51.1l+09 | 34.4441 | 48.5437 | 66.0432 | 36.143. | 27.1427 | 50.1424 | 52.0418 | 53.5415 | 47.9417 | 58.3412 | 41.1419
SPORT 52.7422 | 45.6413 | 50.1427 | 57.1420 | 51.7425 | 28.7414 | 51.2419 | 51.6414 | 49.5417 | 53.4412 | 52.8414 | 46.6418
CoCo 51.8+10 | 56.2413 | 47.1415 | 41.6419 | 36.2426 | 31.0423 | 48.6427 | 55.6418 | 52.6415 | 52.9412 | 56.4417 | 50.1421
DEAL 57.6409 | 53.2+0.7 | 56.2418 | 63.2412 | 48.1415 | 28.3416 | 51.0414 | 58.9416 | 55.3419 | 49.5423 | 52.0427 | 49.7435
SGDA 52.2+3.6 | 59.3433 | 48.6418 | 48.5427 | 41.5414 | 28.2419 | 46.8412 | 48.8419 | 54.0413 | 50.6415 | 49.2415 | 43.7+20
A2GNN 55.2+07 | 50.0+1.8 | 46.7414 | 58.3412 | 48.6411 | 24.9409 | 43.0415 | 52.8410 | 51.3433 | 47.3418 | 50.9414 | 50.4415
StruRW 49.1412 | 58.6418 | 48.1414 | 52.9411 | 45.8427 | 25.8418 | 45.6413 | 55.2+1.0 | 46.3419 | 44.7422 | 53.0413 | 45.6415
PA-BOTH 57.9+08 | 49.2415 | 52.2414 | 59.3423 | 49.9422 | 28.0434 | 51.6421 | 53.3427 | 59.9415 | 53.8412 | 50.7409 | 51.9418
ROAD 54.4421 | 61.0427 | 53.2419 | 60.1424 | 57.5430 | 53.2424 | 53.5422 | 54.7425 | 62.7420 | 55.6417 | 58.3420 | 53.2424
ALEX 50.8+2.0 | 62.7+3.0 | 50.4422 | 61.3420 | 67.9424 | 53.7418 | 53.3419 | 55.8418 | 64.9425 | 59.1420 | 60.3424 | 53.3416

NeGPR 60.7+1.7 | 63.9428 | 58.4422 | 65.8415 | 64.5422 | 59.3419 | 62.6418 | 60.8412 | 66.5425 | 61.6417 | 62.4423 | 58.6415

Table 12: The classification results (in %) on the NCI1 under node density domain shift (source — target). NO, NI, N2 and N3
denote the sub-datasets partitioned with node density. Bold results indicate the best performance.

Methods NO—N1 | NI-NO | NO-N2 | N2—N0 | NO-N3 | N3-NO | NI-N2 | N2-NI1 | NI-N3 | N3-N1 | N2N3 | N3-N2

WL 47.9415 | 53.8+0.7 | 45.7419 | 33.7423 | 34.8411 | 28.3406 | 51.4420 | 51.6418 | 62.0425 | 50.3412 | 47.8109 | 45.8+1.0
PathNN 52.2+21 | 41.1418 | 52.9426 | 64.2414 | 42.3420 | 29.4415 | 51.1423 | 55.7410 | 58.7420 | 47.9422 | 58.1430 | 51.5414
GCN 46.6421 | 63.741.7 | 46.843. | 26.5409 | 32.2424 | 31.1420 | 51.2416 | 48.2415 | 41.0422 | 45.0420 | 55.8415 | 45.7433
GIN 45.5423 | 63.1418 | 47.4432 | 34.4421 | 54.9420 | 30.4415 | 47.2427 | 48.1409 | 61.3417 | 48.5414 | 59.2430 | 49.2425
GAT 47.0421 | 31.4412 | 44.2428 | 62.0415 | 34.2420 | 30.1417 | 45.9425 | 46.8413 | 58.2+19 | 50.1420 | 56.1432 | 47.4409
GMT 53.3411 | 49.5+1.0 | 50.2421 | 49.8417 | 47.8417 | 49.8418 | 50.4426 | 49.8402 | 47.4408 | 49.5418 | 50.2404 | 48.5+02

Co-teaching | 48.6419 | 52.9423 | 47.3418 | 61.4415 | 31.6417 | 28.2420 | 46.8425 | 49.3411 | 44.8422 | 42.2415 | 56.9430 | 46.2423
Taylor-CE 56.0421 | 58.0415 | 45.3424 | 50.9417 | 49.7421 | 28.4419 | 46.2416 | 54.9409 | 59.6418 | 45.9413 | 55.7422 | 53.1415

RTGNN 41.8419 | 61.1421 | 48.6420 | 31.1414 | 39.2418 | 27.6420 | 52.5423 | 52.5412 | 44.0417 | 51.0420 | 59.0424 | 42.6413
OMG 51.3422 | 34.7415 | 47.8419 | 65.5420 | 35.7418 | 27.4417 | 50.4421 | 51.8413 | 54.1418 | 48.3421 | 59.1422 | 40.8416
SPORT 53.0420 | 45.2417 | 50.3421 | 56.7415 | 51.2+16 | 28.9418 | 51.8419 | 52.1420 | 49.2418 | 53.0421 | 52.4414 | 46.9423
CoCo 51.4421 | 56.84+1.7 | 47.4418 | 41.2414 | 36.5419 | 30.7415 | 48.2420 | 55.9421 | 52.3415 | 53.3416 | 56.0422 | 50.4418
DEAL 57.2418 | 53.6421 | 56.641.7 | 63.5419 | 48.4415 | 28.0417 | 51.2420 | 59.1422 | 55.0419 | 49.8416 | 52.2418 | 50.1415
SGDA 52.0+1.9 | 59.7418 | 48.3420 | 48.9416 | 41.8414 | 28.0417 | 46.2421 | 48.6415 | 54.4420 | 50.3417 | 48.9422 | 44.2+16
A2GNN 55.5418 | 50.441.7 | 46.3419 | 58.7416 | 48.3415 | 25.1420 | 42.8418 | 53.1422 | 51.7415 | 47.0417 | 50.7419 | 50.2+16
StruRW 49.3416 | 58.941.7 | 47.8420 | 53.1419 | 45.3416 | 26.0420 | 45.9417 | 55.4421 | 46.5415 | 44.9416 | 53.2418 | 45.8417
PA-BOTH 57.7419 | 49.5416 | 52.4418 | 59.641.7 | 49.5419 | 28.2417 | 51.2420 | 53.5418 | 59.7416 | 54.1421 | 50.9417 | 52.0415
ROAD 54.2+20 | 63.8427 | 56.0422 | 63.2421 | 59.4422 | 50.3415 | 52.5422 | 53.3418 | 56.6420 | 52.2416 | 61.7421 | 52.3417
ALEX 50.9+2.0 | 67.2421 | 56.6431 | 68.9424 | 61.6419 | 53.1425 | 57.4418 | 54.5422 | 60.2423 | 57.8426 | 63.6420 | 55.6423

NeGPR 61.8415 | 65.2+29 | 59.8128 | 64.2124 | 63.1126 | 58.3415 | 61.8426 | 60.5414 | 62.5424 | 59.2416 | 66.1421 | 57.3+2.0



Table 13: The classification results (in %) on the FRANKENSTEIN dataset under graph flux density domain shift (source >
target). FO, Fl, F2 and F3 denote the sub-datasets partitioned with graph flux density. Bold results indicate the best performance.

Methods FO-F1 | FI-—FO | FO-F2 | F2-FO | FO-F3 | F3-FO | FI-F2 | F2>FI1 FI>F3 | F3-F1 F2-F3 | F3-F2
WL 50.4+3.6 | 48.9+0.8 | 49.642.0 | 50.3426 | 49.7434 | 50.7442 | 48.9463 | 50.442.0 | 49.4422 | 49.143.3 | 50.5411 | 49.241.2
PathNN 51.943. 49.3433 | 49.1424 | 49.2421 | 53.0413 | 50.0+0.8 | 49.7425 | 49.5414 | 48.9423 | 50.2411 | 49.543.1 | 50.341.7
GCN 50.3415 | 49.9+3.2 | 49.64+1.0 | 50.0426 | 48.441.1 | 49.4433 | 48.4425 | 49.843.9 | 48.347.0 | 49.2421 | 49.643.7 | 50.645.8
GIN 50.541.7 | 51.1402 | 48.4425 | 50.3423 | 48.941.8 | 49.8421 | 50.9427 | 49.4434 | 55.9411 | 49.643.4 | 52.1417 | 49.5415
GAT 49.44+1.9 | 49.9+0.6 | 47.7417 | 50.0+0.6 | 52.342.9 | 49.5+09 | 49.7444 | 51.4424 | 50.6425 | 49.5414 | 52.5425 | 48.9413
GMT 50.641. 50.6+2.0 | 47.641.2 | 50.4429 | 52.1419 | 48.843. | 48.945.3 | 48.8447 | 56.0415 | 49.943.3 | 52.8421 | 49.042.6
Co-teaching | 52.4414 | 49.4412 | 48.841.2 | 50.0409 | 57.4418 | 50.941.5 | 51.0416 | 49.7424 | 45.0413 | 51.1406 | 49.2+2.0 | 50.4+0.7
Taylor-CE 50.741.5 | 50.4+2.1 | 47.8419 | 49.642.0 | 42.9418 | 49.6421 | 52.7412 | 49.4434 | 56.9417 | 49.0426 | 57.1418 | 49.8+41.9
RTGNN 49.6417 | 49.642.1 | 49.2414 | 49.6416 | 45.14+1.5 | 50.0414 | 51.3419 | 49.8424 | 51.0419 | 50.4425 | 46.9418 | 49.5+1.6
OMG 51.6414 | 50.2+1.4 | 48.9416 | 50.3405 | 55.541.1 | 51.041.8 | 49.841.2 | 50.0402 | 51.6414 | 49.7417 | 45.1414 | 50.0428
SPORT 62.540.9 | 58.6+2.2 | 53.1414 | 53.2412 | 44.742.0 | 51.4409 | 53.9415 | 62.1419 | 42.641.1 | 49.841.6 | 43.2420 | 48.641.8
CoCo 53.4414 | 51.2415 | 53.4486 | 51.1416 | 57.7417 | 52.1408 | 52.9405 | 52.641. 58.741.7 | 51.9409 | 58.1415 | 52.5413
DEAL 57.1416 | 54.9425 | 54.3+0.0 | 52.741.0 | 65.9414 | 52.4402 | 56.841.9 | 51.3406 | 70.241.3 | 51.841.0 | 71.1420 | 51.3406
SGDA 52.740.8 | 51.041.7 | 53.3404 | 55.1413 | 52.8+1.6 | 53.2406 | 54.44+1.2 | 52.341.3 | 51.7410 | 57.341.1 | 52.1412 | 55.1419
A2GNN 54.7413 | 53.040.7 | 53.543.9 | 52.5431 | 51.941.1 | 52.7408 | 54.1428 | 53.0406 | 57.7414 | 52.641.7 | 55.1418 | 53.441.2
StruRW 52.7419 | 50.141.5 | 50.3441 | 49.0421 | 50.8405 | 49.743.6 | 50.5415 | 49.1416 | 50.643.3 | 49.941.2 | 50.7425 | 50.2429
PA-BOTH 51.5416 | 49.04+1.4 | 50.742.2 | 49.042.2 | 48.8425 | 48.640.8 | 50.7407 | 50.441.2 | 51.1411 | 49.5414 | 51.1412 | 49.7428
ROAD 54.3+2.0 | 58.44+1.8 | 55.442.2 | 48.041.7 | 66.142.0 | 52.0423 | 55.3421 | 51.2418 | 65.6421 | 46.3426 | 70.841.8 | 56.642.2
ALEX 56.2+2.0 | 59.8+2.0 | 59.341.9 | 59.0435 | 68.9420 | 54.1425 | 58.641.7 | 56.241.9 | 70.942.2 | 58.041.9 | 72.942.0 | 58.9423
NeGPR 63.9+3.1 | 60.4+2.6 | 60.9427 | 63.4415 | 68.2421 | 59.9426 | 60.641.7 | 59.7419 | 72.1417 | 59.6425 | 74.741.9 | 59.4422

Table 14: The classification results (in %) on the FRANKENSTEIN dataset under edge density domain shift (source — target).
FO, F1, F2 and F3 denote the sub-datasets partitioned with edge density. Bold results indicate the best performance.

Methods FO-+F1 | Fl—FO | FO--F2 | F2—F0 FO—F3 F3-+FO | Fl-F2 | F2-Fl | FI-F3 | F3-F1 | F2-F3 | F3-F2

WL 49.5+1.0 | 50.745.2 | 49.341.7 | 50.2403 | 50.042.4 | 50.141.2 | 50.0+2.4 | 49.1421 | 49.8+3.0 | 50.5413 | 50.6423 | 49.4+4.6
PathNN 49.4+3.0 | 50.143.0 | 52.1423 | 50.4428 | 50.5+11.5 | 51.542.5 | 50.1+2.0 | 50.041.7 | 50.6422 | 49.8+2.4 | 50.743.7 | 50.0+40.7
GCN 49.4454 | 49.543. | 49.1412 | 50.5414 | 50.8+5.5 | 50.8+1.6 | 48.2+5.7 | 51.4+0.5 | 51.4417 | 51.0423 | 53.1412 | 50.1431
GIN 49.5+2.5 | 50.742.0 | 50.849.1 | 50.0423 | 53.141.2 | 50.842.3 | 49.3+1.9 | 51.5+0.5 | 52.6426 | 51.6405 | 52.2427 | 49.342.8
GAT 51.24+5.4 | 48.34+4.2 | 50.6+5.1 | 51.0418 | 50.4418 | 49.9414 | 50.6442 | 51.041.2 | 48.7419 | 50.4+6.2 | 51.041.9 | 49.6+1.9
GMT 53.742.3 | 50.7+0.9 | 52.1+3.8 | 50.4435 | 52.3421 50.2+2.0 | 50.0+2.5 | 48.8+0.7 | 52.9+2.6 | 50.6424 | 50.045.1 | 49.9414
Co-teaching | 47.4+1.6 | 49.641.8 | 51.2419 | 50.042.0 | 47.3415 | 50.2408 | 51.3418 | 49.1407 | 49.1422 | 50.1418 | 50.641.8 | 50.6+41.8
Taylor-CE 53.4427 | 50.9413 | 51.042.7 | 49.441.7 | 53.1412 | 50.8415 | 49.7419 | 50.6416 | 48.8+0.8 | 51.5405 | 46.941.2 | 49.742.0
RTGNN 50.8+1.0 | 48.7+0.8 | 49.6425 | 51.0419 | 52.3416 | 50.8414 | 50.642.1 | 49.4415 | 50.1418 | 50.44+2.6 | 51.341.9 | 50.0+1.7
OMG 51.9+1.4 | 50.0425 | 48.9421 | 49.3403 | 51.7415 | 49.9414 | 51.1416 | 49.7419 | 48.7421 | 50.142.7 | 51.54+1.4 | 50.4+2.6
SPORT 66.5+1.0 | 60.0+0.9 | 55.4+1.6 | 60.0419 | 39.6416 | 44.2412 | 55.4+06 | 59.94+1.1 | 39.642.0 | 46.742.2 | 39.641.7 | 46.8+1.9
CoCo 54.8+0.6 | 52.2+1.0 | 53.5+66 | 51.8+06 | 53.8413 | 52.1406 | 53.3+8.2 | 52.0+0.2 | 53.5+1.9 | 51.5+0.8 | 53.543.9 | 52.2+1.0
DEAL 55.24+3.8 | 51.7404 | 53.7447 | 52.5404 | 53.7418 | 52.44+1.2 | 52.543.9 | 52.6140. | 54.0+1.2 | 53.143.5 | 54.8+9.5 | 53.0+0.7
SGDA 53.341.2 | 52.6+0.1 | 51.5413 | 53.2413 | 54.3409 | 51.1410 | 52.4413 | 54.5+08 | 52.6+0.7 | 53.241.2 | 51.341.8 | 52.1+1.6
A2GNN 56.4+1.0 | 52.0+1.1 | 53.6416 | 52.8413 | 55.1418 | 53.2+1.0 | 53.4+2.0 | 52.2+08 | 55.0+1.1 | 53.0+0.8 | 54.641.1 | 53.3+1.2
StruRW 52.741.9 | 50.1415 | 50.3411 | 49.0421 50.8+0.5 | 50.3+0.9 | 50.5415 | 49.141.6 | 50.6433 | 49.941.2 | 50.741.5 | 50.2+2.9
PA-BOTH 52.34+1.5 | 49.34+1.5 | 50.6428 | 51.1420 | 50.541.5 | 50.8+1.2 | 50.4+1.2 | 49.9+1.0 | 50.4+2.3 | 51.2+0.9 | 49.54+1.4 | 50.2+1.3
ROAD 67.742.4 | 60.1+2.2 | 57.3419 | 60.042.0 | 60.6+42.1 60.041.8 | 55.54+3.1 | 67.7428 | 47.942.7 | 62.4423 | 49.9418 | 53.2+2.0
ALEX 69.542.6 | 61.5+2.0 | 57.942.2 | 62.641.9 | 64.2+1.6 | 61.042.0 | 58.7427 | 65.84+2.4 | 56.2+1.9 | 64.2420 | 60.3421 | 57.5418

NeGPR 70.2+2.0 | 67.642.3 | 62.641.4 | 64.641.7 | 66.0424 | 61.942.1 | 63.642.0 | 63.2428 | 63.3415 | 65.3428 | 59.8421 | 60.2419



Table 15: The classification results (in %) on the FRANKENSTEIN dataset under node density domain shift (source — target).
FO, F1, F2 and F3 denote the sub-datasets partitioned with node density. Bold results indicate the best performance.

Methods FO-F1 | FI-FO | FO-F2 | F2-FO | FO-F3 | F3-F0O | FI-F2 | F2-F1 | FI-F3 | F3-FI | F2-F3 | F3-F2

WL 49.6+0.9 | 49.642.7 | 49.7+0.8 | 48.9414 | 50.2+1.5 | 51.1411 | 51.0431 | 49.343. | 49.2+3.9 | 50.1+1.0 | 51.3442 | 50.7+4.9
PathNN 53.1419 | 49.142.0 | 50.4413 | 49.8412 | 48.841.0 | 50.6409 | 50.4415 | 50.441.1 | 51.2416 | 48.2404 | 49.7422 | 48.5424
GCN 49.44+1.9 | 49.9+0.6 | 47.7417 | 50.0+0.6 | 52.342.9 | 49.5+09 | 49.7444 | 51.4424 | 50.6425 | 49.5414 | 52.5425 | 48.9413
GIN 46.34+1.7 | 50.3405 | 51.441. | 49.7403 | 51.7+2.0 | 49.7+0.7 | 51.8+1.0 | 50.2+1.5 | 48.5421 | 50.3+1.2 | 51.942.7 | 48.7422
GAT 50.041.7 | 49.742.5 | 49.3+1.6 | 50.4419 | 49.7447 | 49.9+0.8 | 49.8432 | 50.443.3 | 51.3423 | 49.4419 | 51.1419 | 48.2413
GMT 53.4419 | 49.8+0.4 | 51.5+1.6 | 49.3413 | 47.342.0 | 49.2427 | 50.543.8 | 49.741.3 | 47.342.0 | 49.741.9 | 49.141.0 | 49.2+04
Co-teaching | 54.0416 | 50.4426 | 49.8+1.3 | 50.3413 | 50.0+2. 49.640.9 | 48.0425 | 48.8412 | 49.6413 | 48.8+0.7 | 48.8423 | 49.0+2.0
Taylor-CE 53.942.0 | 50.340.5 | 52.341.7 | 49.9+0.6 | 47.81. 49.840.5 | 52.2419 | 50.6412 | 48.2418 | 50.2415 | 48.0428 | 49.3122

3
8

RTGNN 53.741.7 | 50.2+2.4 | 48.7426 | 49.5415 | 47.841.1 | 50.0414 | 51.6414 | 49.4416 | 51.542.0 | 48.941. | 48.1414 | 49.7417
3
4

OMG 50.1412 | 49.84+2.3 | 51.44+2.2 | 50.541.6 | 49.3+2. 50.042.0 | 51.2+1.2 | 50.7+1.0 | 51.441.1 | 50.7+0.9 | 49.7405 | 50.4+41.5
SPORT 67.3412 | 56.8423 | 57.841.7 | 56.8409 | 39.541: 48.841.7 | 57.8412 | 67.3406 | 39.5423 | 46.5421 | 39.7411 | 42.2416
CoCo 54.6414 | 52.6404 | 54.041.6 | 52.7407 | 54.1489 | 52.5408 | 52.0404 | 52.3404 | 54.541.0 | 53.3403 | 53.542.2 | 52.7+0.1
DEAL 56.0+2.0 | 53.3419 | 53.2428 | 53.4406 | 53.1425 | 53.1406 | 53.3456 | 52.0406 | 53.541.0 | 53.2406 | 54.5414 | 53.2405
SGDA 52.2413 | 53.4409 | 52.441.2 | 54.1411 | 55.2416 | 51.3407 | 52.2409 | 54.5413 | 53.641.8 | 52.542.2 | 53.941.8 | 51.7422
A2GNN 56.0414 | 52.2416 | 53.3413 | 52.5411 | 54.7415 | 52.941.7 | 54.041.3 | 52.5403 | 52.742.0 | 51.841.0 | 54.341.9 | 52.3405
StruRW 51.0413 | 49.8+2. 50.341.0 | 50.34+1.4 | 50.341.9 | 50.54+1.0 | 51.141.2 | 50.2406 | 50.94+1.7 | 49.4+0.8 | 49.941.2 | 49.342.2
PA-BOTH 51.3414 | 50.04+1.0 | 51.2+2.0 | 50.1413 | 49.44+3.3 | 49.7413 | 50.8+1.8 | 51.141.2 | 52.1433 | 49.2415 | 49.2427 | 49.4+2.0
ROAD 67.8423 | 56.8+2.8 | 56.7424 | 57.1423 | 58.5416 | 57.041.9 | 57.942.0 | 67.4421 | 47.943.0 | 61.0421 | 46.0424 | 54.342.0
ALEX 69.2+2.2 | 60.2+1.8 | 60.141.7 | 61.4425 | 58.3419 | 61.1424 | 61.8417 | 68.8415 | 53.2421 | 61.5428 | 60.042.0 | 59.741.7

NeGPR 71.7+2.0 | 60.6416 | 59.642.1 | 61.541.7 | 62.7419 | 60.0+2.0 | 62.6413 | 70.3426 | 58.9416 | 62.542.0 | 60.642.4 | 58.4+42.2

Table 16: The classification results (in %) on the MUTAGENICITY dataset under graph flux density domain shift (source >
target). MO, M1, M2, and M3 denote the sub-datasets partitioned with node density. Bold results indicate the best performance.

Methods MO-—M1 | M1-MO | MO-+M2 | M2—MOo | M0O-M3 | M3-—+MO | MI-M2 | M2—>MI1 | M1-M3 | M3—M1 | M2—>M3 | M3—>M2

WL 58.1+42.1 47.6414 53.342.2 54.8+43.0 45.7413 47.0418 53.342.6 64.2+2.1 45.340.9 40.7+42.3 46.0+1.0 45.5+2.5
PathNN 45.0+2.1 61.7419 58.443.2 53.5+41.1 49.0+0.7 46.342.0 58.2+42.5 67.1+41.8 50.2+2.4 57.3415 52.4+0.9 60.2+1.8
GCN 61.1418 52.0+42.3 42.9411 47.1+0.8 46.7+41.2 56.4417 51.4+43.0 33.4413 54.9+0.6 37.142.4 50.6+1.5 58.2+42.2
GIN 54.041.7 48.2+42.1 51.342.3 58.4+0.9 46.2+1.3 47.2415 51.8+42.0 55.0+2.4 47.6+42.1 55.841.2 54.0+1.5 56.0+3.1
GAT 59.0+2.2 56.342.7 63.7+1.9 56.442.4 48.643.2 53.0+1.6 51.5414 67.342.5 44.8+41.8 48.5+0.7 46.3+42.0 56.3+41.0
GMT 52.1+41.6 50.7+3.1 51.0+5.8 49.4+1.2 55.8+1.7 50.6+0.7 51.5+42.1 50.3+4.5 45.5427 49.6+4.6 S7.141.1 51.441.2

Co-teaching | 56.4+2.1 62.2417 | 61.2425 | 50.5413 | 42.9420 | 53.7419 | 55.1423 | 61.3414 | 45.9422 | 39.9411 48.1424 | 53.8+0.7
Taylor-CE 56.7£1.2 | 53.6423 | 51.2418 | 61.8409 | 55.143.0 | 47.6422 | 48.3414 | 57.9416 | 50.2425 | 55.341. 50.7417 | 53.9+43.2

RTGNN 66.9+2.0 49.7413 40.7419 53.4+43.0 48.641.7 60.2+2.3 55.4+0.8 30.5+2.0 59.143.1 43.9415 55.1+1.0 62.942.4
OMG 63.2+1.5 61.340.8 59.142.2 54.0+41.9 47.9413 56.1+2.5 59.0+41.7 68.5+2.8 46.541.1 43.340.7 50.0+1.0 59.7+42.1
SPORT 60.7+2.0 53.2415 58.343.3 58.0+41.2 49.2+42.3 57.143.1 54.6+40.8 67.342.6 45.5+0.7 59.4+1.0 49.9+2.1 59.9+2.5
CoCo 54.442.2 51.7416 49.7+0.9 56.0+43.2 45.1427 47.141.0 55.943.3 57.9+2.0 50.7+1.8 36.5413 49.7425 52.1+40.6
DEAL 59.1+43.0 59.6+42.2 56.7417 56.0+0.8 52.1413 56.5+0.9 57.642.5 70.9+1.6 44.3414 54.143.1 50.6+2.0 57.0+41.2
SGDA 61.441.5 45.1+0.9 58.041.7 52.0+2.0 51.24+1.2 41.1407 59.4+42.3 69.1+43.4 45.1411 48.5+42.2 46.3+40.6 54.0+2.0
A2GNN 57.0418 50.4+2.1 57.641.5 59.5+2.0 54.0+1.4 45.8+0.9 49.9+43.3 63.7+2.5 41.5+1.0 56.0+0.7 46.5418 62.341.2
StruRW 61.742.3 54.5+41.4 48.2418 56.0+0.9 46.3+41.6 61.1+43.0 55.7+2.1 42.9+0.5 53.341.2 51.4+0.9 52.843.1 61.7424
PA-BOTH 60.5+2.0 54.8+41.1 57.64+1.9 59.4+42.3 53.0+1.4 54.1+42.2 60.7+3.0 67.1+0.8 52.142.3 59.141.7 44.7425 55.3413
ROAD 56.6+2.2 61.3413 52.2+2.1 59.4+2.0 55.0+2.5 51.142.3 59.1+42.2 63.8+1.9 56.6+2.2 59.4+3.0 58.7+2.0 60.1+41.8
ALEX 60.8+2.4 63.343.3 64.1+2.6 64.1+42.4 60.5+1.9 56.9+2.9 59.6+2.0 62.5+2.3 63.7+2.6 51.941.8 61.2419 63.6+43.0

NeGPR 70.1421 | 65.6418 | 66.7424 | 63.9417 | 59.7420 | 65.9416 | 65.842.3 | 72.3421 | 64.2412 | 63.6418 | 59.1423 | 65.6+2.0


Table 17: The classification results (in %) on the MUTAGENICITY dataset under edge density domain shift (source — target).
MO, M1, M2, and M3 denote the sub-datasets partitioned with edge density. Bold results indicate the best performance.

Methods M1-—MO | MO-—M2 | M2-MO | MO-—M3 | M3-—+MO | M1-+M2 | M2-—M1 | MI-—M3 | M3->M1 | M2->M3 | M3-M2
WL 48.8+41.2 52.9+1.2 54.242.4 46.2+1.8 47.443.4 53.942.7 63.9+2.1 44.8417 41.3411 46.7+43.2 45.743.9
PathNN 60.3+42.7 59.5+2.8 52.8+1.5 48.7419 47.9+4.1 57.4+0.9 68.2+1.5 50.6+1.6 58.0+42.7 51.2414 59.6+0.6
GCN 52.0+0.9 43.6418 47.8414 47.143.3 56.2+2.6 51.8+41.9 34.2+2.0 54.2+1.5 36.6+0.7 50.8+2.2 57.9+1.5
GIN 47.7414 49.9+3.6 57.0+42.9 45.5+1.4 46.5+4.3 52.0+43.5 53.943.1 46.7419 54.7417 55.44+2.1 55.742.8
GAT 56.0+41.7 63.4414 57.1+40.8 49.3+42.6 52.343.1 52.843.3 68.4+2.5 45.0414 48.8+43.3 45.7429 55.8418
GMT 49.9+3.0 51.641.3 51.5+1.6 50.6+1.6 49.3415 53.342.7 50.4+2.9 49.4+2.0 52.141.0 50.8+1.1 50.5+1.4
Co-teaching 61.0436 | 60.8+2.1 49.9418 | 43.6407 | 53.3417 | 55.642.6 | 62.0421 46.4415 39.1413 | 48.4419 | 54.0426
Taylor-CE 52.4417 | 50.3423 | 60.9418 | 53.9433 | 46.9406 | 49.4418 | 56.1414 | 49.941.7 | 55.6422 | 49.9426 | 51.7415
RTGNN 48.1+42.6 40.3+42.4 52.2+1.2 49.2+0.7 60.9+1.6 56.0+2.3 31.2427 59.4+1.6 43.3+40.9 54.444.2 62.4+0.5
OMG 60.9+41.6 58.6+2.1 53.4417 47.2+1.6 55.9+0.9 58.0+4.7 68.343.3 47 141.9 44.1+41.8 49.6415 59.5+1.7
SPORT 54.142.7 56.74+2.4 S7.141.8 48.0+41.9 57.943.3 53.143.6 66.8+1.5 45.8419 60.7+0.7 48.743.6 59.6+1.6
CoCo 52.2+0.5 47 A417 57.8+1.6 45.8+42.3 46.5415 55.1+40.9 61.4418 50.3+0.4 37.7433 50.643.7 50.8+2.6
DEAL 60.9+41.3 56.2+1.6 56.9+41.9 50.3+0.7 56.2+2.5 59.3+42.0 67.8+3.1 46.6414 54.641.4 S1L.741.1 56.2+1.5
SGDA 46.4+42.3 57.24+2.1 54.542.7 49.3+40.8 41.6417 56.1+0.9 68.0+2.3 46.0+0.8 48.1415 46.5417 51.041.3
A2GNN 52.4+41.8 58.142.7 56.5+1.5 52.54+1.7 46.6+0.4 48.9+0.9 65.2+1.1 40.6+2.6 53.542.9 49.8+2.3 60.1+41.8
StruRW 55.4+0.8 45.9419 58.0+41.7 44.7422 61.9+1.5 55.2+1.8 39.6+0.6 52.6+1.4 51.8+42.4 53.1418 59.7+1.6
PA-BOTH 56.6+42.8 58.34+2.1 60.1+41.9 51.6+0.9 53.5414 60.341.8 67.9+2.2 50.6+1.5 60.5+1.8 46.0+4.1 57.2417
ROAD 62.6+42.8 61.5+2.0 57.0+1.6 55.5+1.9 52.0+2.2 60.342.7 71.1422 53.5419 61.542.7 54.0+2.3 57.4419
ALEX 62.9418 64.7+2.0 63.4+42.3 56.5+2.4 54.8+1.6 61.442.5 70.342.3 55.0+1.5 61.2418 59.5+2.9 57.5423
NeGPR 61.7+42.5 64.5+1.8 62.9+42.3 59.7+41.4 64.341.5 62.442.4 70.9+42.5 60.8+2.4 65.1415 60.2+2.0 65.4415

Table 18: The classification results (in %) on the MUTAGENICITY dataset under node density domain shift (source — target).
MO, M1, M2, and M3 denote the sub-datasets partitioned with node density. Bold results indicate the best performance.

Methods MO-—M1 | M1-+MO | MO-+M2 | M2—MO | M0O-M3 | M3-+MO | MI-M2 | M2—>MI1 | M1-M3 | M3—M1 | M2—M3 | M3->M2
WL 56.743.8 50.9+4.5 54.4448 51.942.1 46.441.5 45.9413 55.142.2 64.5+1.8 42.2412 43.0+43.9 46.6+43.1 48.6+0.8
PathNN 43.7422 59.8+4.1 56.9+3.3 51.7442 50.1+4.3 45.2+2.6 58.0+42.5 69.2+3.0 51.1421 55.842.2 50.343.4 59.2+1.6
GCN 61.8+2.0 51.0+42.7 41.5+43.0 48.2+4.2 46.743.9 57.1414 53.5+4.0 35.5+4.3 56.441.5 34.342.5 50.1+41.4 59.743.9
GIN 48.9418 48.0+42.3 48.2+42.2 55.743.5 47.5+43.1 44.5423 53.4+43.0 55.8+2.9 47.2437 52.8+42.8 56.641.7 55.143.2
GAT 59.841.7 53.241.6 63.24+2.4 58.2+2.0 52.1+4.4 53.143.6 50.6+4.1 66.8+0.7 45.744.0 47.6414 47.3411 56.1+44.9
GMT 54.741.2 51.0+0.9 53.24+1.9 50.5+0.3 50.5+2.8 50.5+0.6 53.2+1.6 48.441.1 50.8+1.8 51.1418 50.1+2.1 49.8+1.1

Co-teaching | 55.4415 | 60.8+1.0 | 63.2432 | 51.2427 | 42.0447 | 55.4440 | 55.7419 | 61.3433 | 48.4446 | 38.2445 | 49.5432 | 53.7428
Taylor-CE 56.5433 | 51.3438 | 48.9431 62.5423 | 54.6+2.1 46.8444 | 48.643.7 | 58.3417 | 51.4446 | 53.3443 | 51.8424 | 52.7419

RTGNN 68.7+41.3 46.6+44.8 42.9+3.0 53.443.4 47. 241.5 60.5+4.7 55.743.5 28.54+2.7 60.4+2.0 41.5+4.0 52.94+2.8 62.2+42.3
OMG 63.0+4.2 61.943.6 57.743.5 55.0+42.3 45.4+1.8 58.4419 59.742.2 68.9+3.7 46.0+2.9 41.743.6 49.4437 61.7414
SPORT 61.742.7 54.3+44.8 56.0+4.2 55.9+42.9 47.9+42.6 60.7+4.5 53.5+1.6 64.5+2.5 45.5429 62.743.2 47.643.8 57.0+4.9
Coco 54.143.7 51.343.4 45.243.3 59.9+43.2 46.4+4.1 45.0+4.4 56.5+1.3 58.8+2.8 51.8411 37.54+1.2 52.9+4.6 50.9+41.9
DEAL 59.8+3.8 60.8+42.1 54.2+2.1 57.6+4.9 50.0+2.6 56.0+4.5 59.6+41.9 68.7+2.1 48.7+4.0 52.143.2 51.143.5 57.242.6
SGDA 58.143.1 46.5+2.4 55.9+3.0 57.0+4.3 48.643.1 43.5415 53.942.7 70.342.4 45.0+3.4 46.2+42.8 47.1+41.0 52.2+4.9
A2GNN 51.4+41.6 57.3444 57.6+2.6 51.943.4 44.644.9 48.0+2.0 65.6+1.2 42.3445 56.3414 52.0+2.0 57.443.9

StruRW . . 56.1+42.0 43.0+4.7 56.6+41.2 44.9+42.2 59.743.3 55.742.9 38.643.6 53.843.8 52.242.7 52.44+2.3 58.0+41.8
PA-BOTH 60.9+2.8 55.8+44.7 60.7+2.3 60.4+4.8 51.1+1.6 51.4417 62.342.5 66.8+3.0 49.744.6 60.6+3.6 48.2+3.9 57.8443

ROAD 64.341.8 60.6+41.7 61.0+2.9 57.7+42.0 56.9+2.7 56.4418 63.2+2.1 68.3+2.0 47.7417 59.2+2.6 51.2419 63.142.2
ALEX 65.342.7 63.542.3 64.2431 65.8+42.1 56.4+2.2 54.1+42.6 64.2+1.9 70.0+2.0 56.5+1.9 62.142.1 58.5+2.2 62.0+2.5

NeGPR 70.1421 65.6+41.8 63.74+2.4 63.941.7 58.7+2.0 61.9+1.6 65.8+42.1 71.3417 62.2419 63.6418 60.1+2.3 64.6+42.0