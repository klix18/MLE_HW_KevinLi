# RAG Pipeline for arXiv cs.CL Papers
### This project implements a Retrieval-Augmented Generation (RAG) pipeline over a collection of arXiv papers.
It scrapes PDFs, extracts text, chunks content, embeds using SentenceTransformers, builds a FAISS vector index, and finally queries with OpenAIâ€™s GPT models.

## ğŸ“ Project structure (key files)

HW_4_RAG_w_ARXIV/
â”œâ”€ master_setup.py
â”œâ”€ query.py
â”œâ”€ step1_scrape.py
â”œâ”€ step2_extract.py
â”œâ”€ step3_chunk.py
â”œâ”€ step4_embed.py
â”œâ”€ step5_faiss.py
â”œâ”€ pdfs/ # downloaded PDFs (created at runtime)
â”œâ”€ texts.json # extracted text per PDF (created)
â”œâ”€ chunks.json # chunked text per PDF (created)
â”œâ”€ documents.json # [{chunk, embedding}] per PDF (created)
â”œâ”€ id_mapping.json # FAISS id â†’ (pdf, chunk_idx) mapping (created)
â”œâ”€ faiss.index # FAISS vector index (created)
â””â”€ .env # your OpenAI API key (you create)

## ğŸ“¦ Requirements
Make sure you have Python 3.9+ and virtualenv or venv set up.

```
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

