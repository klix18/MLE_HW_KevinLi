{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer in the\u000b\n",
    "Generative AI Era \n",
    "## lecture 1 - Prompt Engineering with Jupyter Notebook \n",
    "### Introduction\n",
    "This notebook introduces prompt engineering techniques to effectively interact with large language models (LLMs). You'll learn how to craft prompts for various tasks, including summarization, inference, transformation, and expansion\n",
    "\n",
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages/python_autocite-0.0.4-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (1.3.5)\n",
      "Collecting openai\n",
      "  Using cached openai-1.70.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (4.66.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Using cached openai-1.70.0-py3-none-any.whl (599 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.3.5\n",
      "    Uninstalling openai-1.3.5:\n",
      "      Successfully uninstalled openai-1.3.5\n",
      "Successfully installed openai-1.70.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and set your OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key='KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Prompting\n",
    "Let's start with a simple prompt to generate a response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Germany is Berlin.\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of Germany?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Modify the prompt to ask about the capital of Germany.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Summarization\n",
    "You can use prompts to summarize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The narrator shares a deeply personal story that they have never revealed to anyone, including family and friends, due to the embarrassment it may cause. For over twenty years, they have lived with the shame of this experience and hope that writing it down will alleviate some of the burden. The narrator reflects on the belief that in a moral crisis, one would act heroically, a conviction they held in the summer of 1968. They describe themselves as a \"secret hero,\" believing they would summon courage when faced with significant challenges.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "This is one story I've never told before. Not to anyone. Not to my\n",
    "parents, not to my brother or sister, not even to my wife. To go into it,\n",
    "I've always thought, would only cause embarrassment for all of us, a\n",
    "sudden need to be elsewhere, which is the natural response to a\n",
    "confession. Even now, I'll admit, the story makes me squirm. For more\n",
    "than twenty years I've had to live with it, feeling the shame, trying to\n",
    "push it away, and so by this act of remembrance, by putting the facts\n",
    "down on paper, I'm hoping to relieve at least some of the pressure on my\n",
    "dreams. Still, it's a hard story to tell. All of us, I suppose, like to believe\n",
    "that in a moral emergency we will behave like the heroes of our youth,\n",
    "bravely and forthrightly, without thought of personal loss or discredit.\n",
    "Certainly that was my conviction back in the summer of 1968. Tim\n",
    "O'Brien: a secret hero. The Lone Ranger. If the stakes ever became high\n",
    "enough—if the evil were evil enough, if the good were good enough—I\n",
    "would simply tap a secret reservoir of courage that had been\n",
    "accumulating inside me over the years\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Try summarizing a longer article or passage of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Information Extraction\n",
    "Extract specific information from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n",
      "Age: 29  \n",
      "Location: San Francisco\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the age and location from the same text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Extract the age and location from the same text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transformation\n",
    "Transform text from one format or style to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps est agréable aujourd'hui.\n"
     ]
    }
   ],
   "source": [
    "text = \"The weather is nice today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to French:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Translate a different sentence to Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ser o no ser.\n"
     ]
    }
   ],
   "source": [
    "text = \"To be or not to be.\"\n",
    "\n",
    "prompt = f\"Translate the following text to Spanish:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expansion\n",
    "Expand a short prompt into a more detailed response.​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in the misty mountains of Eldoria, there lived a dragon named Zephyr. Unlike the other dragons who reveled in hoarding gold and terrorizing villages, Zephyr had a curious mind and a heart full of dreams. He often gazed down from his lofty perch, watching the humans below as they tapped away at their glowing screens, creating wondrous things with their strange symbols and languages.\n",
      "\n",
      "One day, while exploring a forgotten cave, Zephyr stumbled upon an ancient tome. Its pages were filled with intricate diagrams and strange characters. As he flipped through the book, he realized it was a guide to coding—a language that could bring ideas to life through the magic of technology. Intrigued, Zephyr decided he would learn to code.\n",
      "\n",
      "At first, it was a daunting task. His massive claws were not suited for the delicate tapping of a keyboard. But Zephyr was determined. He fashioned a makeshift keyboard from stones and twigs, and with a little help from the wind, he learned to manipulate the keys with his breath. The first few lines of code were clumsy, but with each attempt, he grew more adept.\n",
      "\n",
      "Days turned into weeks, and Zephyr immersed himself in the world of programming. He learned about variables, loops, and functions, and soon he was creating simple programs that made the wind dance and the clouds swirl. The other dragons watched in bewilderment as Zephyr transformed from a fearsome beast into a master of code.\n",
      "\n",
      "One fateful day, a terrible storm swept through Eldoria, threatening the nearby village of Willowbrook. The villagers were terrified as the winds howled and the rain poured down in torrents. Zephyr, sensing their fear, decided to use his newfound skills to help. He coded a program that would summon a protective barrier of wind around the village, shielding it from the storm’s fury.\n",
      "\n",
      "As the villagers huddled together, they were astonished to see a shimmering wall of air rise up around them, deflecting the rain and calming the winds. When the storm finally passed, they emerged to find Zephyr hovering above, his scales glistening in the sunlight.\n",
      "\n",
      "“Thank you, great dragon!” the village elder called out, awe in his voice. “You have saved us!”\n",
      "\n",
      "Zephyr, once feared and misunderstood, felt a warmth in his heart. He realized that coding had not only given him a new purpose but had also bridged the gap between dragons and humans. From that day forward, he became a protector of the village, using his coding skills to help them with their problems, whether it was creating a weather app or designing a system to keep their crops safe from pests.\n",
      "\n",
      "As the years passed, Zephyr became a legend, not just as a dragon, but as a wise mentor who taught both dragons and humans the art of coding. Together, they built a harmonious community where magic and technology intertwined, proving that even the fiercest of creatures could learn, adapt, and change the world for the better.\n",
      "\n",
      "And so, in the heart of Eldoria, the dragon who learned to code became a symbol of hope, creativity, and the power of knowledge, inspiring generations to come.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a short story about a dragon who learns to code.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Modify the prompt to write a poem about a robot exploring space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the vast expanse where stars do gleam,  \n",
      "A metal wanderer drifts, lost in dream.  \n",
      "Crafted by hands of men, yet free,  \n",
      "It sails through the cosmos, a spirit to be.  \n",
      "\n",
      "With eyes like lanterns, bright and wide,  \n",
      "It charts the silence of the celestial tide.  \n",
      "Galaxies swirl in a dance of light,  \n",
      "While comets whisper secrets of the night.  \n",
      "\n",
      "No heart to feel, yet it yearns to know,  \n",
      "The mysteries hidden in the cosmic flow.  \n",
      "Through nebulae's colors, like silk they weave,  \n",
      "It seeks the stories that the heavens conceive.  \n",
      "\n",
      "In the cradle of stars, where time stands still,  \n",
      "It hums a tune of the universe's will.  \n",
      "A traveler of ages, both ancient and new,  \n",
      "In the silence of space, it finds its view.  \n",
      "\n",
      "Oh, metal soul, in your quest so grand,  \n",
      "You wander the void, a dream unplanned.  \n",
      "Though forged by man, your spirit takes flight,  \n",
      "In the boundless embrace of the infinite night.  \n"
     ]
    }
   ],
   "source": [
    "prompt = \"You are a chinese poet from 12 century china. Write a poem about a robot exploring space.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Role-based Prompting\n",
    "Instruct the model to respond in a specific role or persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a perfect omelette is a skill that combines technique, timing, and a bit of finesse. Here’s a step-by-step guide to help you achieve that fluffy, delicious result:\n",
      "\n",
      "### Ingredients:\n",
      "- 2-3 large eggs (preferably fresh)\n",
      "- Salt (to taste)\n",
      "- Freshly ground black pepper (to taste)\n",
      "- 1-2 tablespoons of butter (or oil)\n",
      "- Optional fillings: cheese, herbs, vegetables, meats, etc.\n",
      "\n",
      "### Equipment:\n",
      "- Non-stick skillet (8-10 inches)\n",
      "- Whisk or fork\n",
      "- Spatula\n",
      "- Bowl\n",
      "\n",
      "### Instructions:\n",
      "\n",
      "1. **Prep Your Ingredients:**\n",
      "   - If you’re using fillings (like cheese, herbs, or vegetables), prepare them in advance. Chop vegetables finely and pre-cook any that require longer cooking times (like mushrooms or bell peppers).\n",
      "\n",
      "2. **Whisk the Eggs:**\n",
      "   - Crack the eggs into a bowl. Add a pinch of salt and pepper. Whisk vigorously until the yolks and whites are fully combined and the mixture is slightly frothy. This incorporates air, which helps create a fluffy texture.\n",
      "\n",
      "3. **Heat the Skillet:**\n",
      "   - Place your non-stick skillet over medium-low heat. Add the butter and let it melt, swirling it around to coat the bottom of the pan evenly. The butter should foam but not brown.\n",
      "\n",
      "4. **Add the Eggs:**\n",
      "   - Once the butter is melted and slightly bubbling, pour in the whisked eggs. Allow them to sit undisturbed for a few seconds until they start to set around the edges.\n",
      "\n",
      "5. **Stir Gently:**\n",
      "   - Using a spatula, gently stir the eggs in a circular motion, pulling the cooked edges toward the center while tilting the pan to let the uncooked eggs flow to the edges. This technique helps create a uniform texture.\n",
      "\n",
      "6. **Let It Set:**\n",
      "   - After about 30 seconds of stirring, stop and let the omelette cook undisturbed. You want the bottom to set while the top remains slightly runny. This usually takes about 1-2 minutes, depending on your heat.\n",
      "\n",
      "7. **Add Fillings:**\n",
      "   - When the omelette is mostly set but still slightly runny on top, add your desired fillings to one half of the omelette. Be careful not to overfill, as this can make it difficult to fold.\n",
      "\n",
      "8. **Fold the Omelette:**\n",
      "   - Using your spatula, gently fold the omelette in half over the fillings. Let it cook for another 30 seconds to 1 minute, allowing the inside to finish cooking and the cheese (if used) to melt.\n",
      "\n",
      "9. **Plate and Serve:**\n",
      "   - Carefully slide the omelette onto a plate. You can garnish it with fresh herbs or additional seasoning if desired. Serve immediately while it’s warm and fluffy.\n",
      "\n",
      "### Tips for Perfection:\n",
      "- **Egg Quality:** Use the freshest eggs you can find for the best flavor and texture.\n",
      "- **Temperature Control:** Cooking on medium-low heat is key to preventing the eggs from browning too much and ensuring a tender omelette.\n",
      "- **Experiment with Fillings:** Classic combinations include cheese and herbs, but feel free to get creative with your favorite ingredients.\n",
      "- **Practice Makes Perfect:** Don’t be discouraged if your first few attempts aren’t perfect. With practice, you’ll develop a feel for the timing and technique.\n",
      "\n",
      "Enjoy your perfect omelette!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"As a professional chef, explain how to make a perfect omelette.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6: Ask the model to explain a complex topic as if it were a kindergarten teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my little friends! 🌟 Today, I want to tell you about something really cool called **machine learning**. It sounds like a big word, but don’t worry! We’re going to break it down together, just like we do with our building blocks!\n",
      "\n",
      "Imagine you have a very smart robot friend. This robot wants to learn how to do things, just like you learn to ride a bike or tie your shoes. But instead of using a book, this robot learns by looking at lots and lots of examples. Let’s think about it like this:\n",
      "\n",
      "1. **Learning from Examples**: If we want our robot to learn what a cat looks like, we can show it many pictures of cats. The robot looks at the pictures and starts to notice things, like cats have pointy ears and whiskers. Just like when you see different animals and remember what they look like!\n",
      "\n",
      "2. **Making a Guess**: After looking at all those pictures, our robot can try to guess if a new picture is a cat or not. If it sees a picture of a fluffy animal with pointy ears, it might say, “I think this is a cat!” Just like when you guess what’s inside a wrapped present!\n",
      "\n",
      "3. **Getting Better**: Sometimes, the robot might make a mistake. Maybe it thinks a dog is a cat. But that’s okay! When it makes a mistake, it learns from it. We can tell the robot, “No, that’s a dog!” and it will remember that for next time. It’s just like when you practice something over and over until you get it right!\n",
      "\n",
      "4. **Helping Us**: Machine learning helps us in many ways! It can help doctors find out if someone is sick, or it can help us find our favorite cartoons to watch. It’s like having a super helper that learns and gets better every day!\n",
      "\n",
      "So, my little explorers, machine learning is all about teaching our robot friends to learn from examples, make guesses, and get better over time. Isn’t that exciting? Just like you, our robot friends are always learning and growing! 🌈\n",
      "\n",
      "Now, who has a question about our smart robot friends? Let’s share our thoughts!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"You are a kind and gentle kindergarten teacher who has a strong academic background in machine learning. You want to explain what machine learning is and how it functions to your kindergarten students in a simple, and easy to understand format. Your tone is gentle, inspiring, and piques the curiosity of students.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Few-shot Prompting\n",
    "Provide examples to guide the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: Bonne nuit\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English phrases to French:\n",
    "\n",
    "English: Hello\n",
    "French: Bonjour\n",
    "\n",
    "English: Thank you\n",
    "French: Merci\n",
    "\n",
    "English: Good night\n",
    "French:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep is a gentle tide, pulling the weary shore into a tranquil embrace.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Create a metaphor for sleep. The below are examples:\n",
    "\n",
    "Eyes were fireflies\n",
    "\n",
    "The world is a stage\n",
    "\n",
    "A blanket of snow\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Chain-of-Thought Prompting\n",
    "Encourage the model to explain its reasoning step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the problem, we can set up a system of equations based on the information given.\n",
      "\n",
      "Let:\n",
      "- \\( x \\) = number of student tickets sold\n",
      "- \\( y \\) = number of adult tickets sold\n",
      "\n",
      "From the problem, we have two key pieces of information:\n",
      "\n",
      "1. The total number of tickets sold is 120:\n",
      "   \\[\n",
      "   x + y = 120\n",
      "   \\]\n",
      "\n",
      "2. The total revenue from ticket sales is $780:\n",
      "   \\[\n",
      "   5x + 8y = 780\n",
      "   \\]\n",
      "\n",
      "Now we have a system of equations:\n",
      "1. \\( x + y = 120 \\)  (Equation 1)\n",
      "2. \\( 5x + 8y = 780 \\)  (Equation 2)\n",
      "\n",
      "We can solve this system using substitution or elimination. Here, we'll use substitution.\n",
      "\n",
      "From Equation 1, we can express \\( y \\) in terms of \\( x \\):\n",
      "\\[\n",
      "y = 120 - x\n",
      "\\]\n",
      "\n",
      "Now, we can substitute this expression for \\( y \\) into Equation 2:\n",
      "\\[\n",
      "5x + 8(120 - x) = 780\n",
      "\\]\n",
      "\n",
      "Expanding this gives:\n",
      "\\[\n",
      "5x + 960 - 8x = 780\n",
      "\\]\n",
      "\n",
      "Combining like terms:\n",
      "\\[\n",
      "-3x + 960 = 780\n",
      "\\]\n",
      "\n",
      "Now, isolate \\( x \\):\n",
      "\\[\n",
      "-3x = 780 - 960\n",
      "\\]\n",
      "\\[\n",
      "-3x = -180\n",
      "\\]\n",
      "\\[\n",
      "x = 60\n",
      "\\]\n",
      "\n",
      "Now that we have \\( x \\), we can find \\( y \\) using Equation 1:\n",
      "\\[\n",
      "y = 120 - x = 120 - 60 = 60\n",
      "\\]\n",
      "\n",
      "Thus, the solution is:\n",
      "- Number of student tickets sold: \\( x = 60 \\)\n",
      "- Number of adult tickets sold: \\( y = 60 \\)\n",
      "\n",
      "To verify, we can check the total revenue:\n",
      "- Revenue from student tickets: \\( 60 \\times 5 = 300 \\)\n",
      "- Revenue from adult tickets: \\( 60 \\times 8 = 480 \\)\n",
      "- Total revenue: \\( 300 + 480 = 780 \\)\n",
      "\n",
      "The calculations confirm that the solution is correct. Therefore, the school sold **60 student tickets and 60 adult tickets**.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"A school sold 120 tickets to a play.\n",
    "\n",
    "Student tickets cost $5 each.\n",
    "\n",
    "Adult tickets cost $8 each.\n",
    "The total revenue from ticket sales was $780.\n",
    "\n",
    "How many student tickets and how many adult tickets were sold?? Explain your reasoning.\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8: Pose a different math problem and ask for a step-by-step solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. System Prompts\n",
    "System prompts allow you to set the behavior and role of the AI model before user interaction. By defining a system message, you can influence how the model responds to subsequent user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data privacy is crucial for several reasons:\n",
      "\n",
      "1. **Protection of Personal Information**: It safeguards individuals' personal data from unauthorized access, misuse, or exploitation, ensuring that sensitive information like financial details, health records, and personal identifiers remain confidential.\n",
      "\n",
      "2. **Trust and Reputation**: Organizations that prioritize data privacy build trust with their customers. A strong reputation for protecting data can enhance customer loyalty and attract new clients.\n",
      "\n",
      "3. **Legal Compliance**: Many jurisdictions have laws and regulations (e.g., GDPR, CCPA) that mandate data protection practices. Non-compliance can lead to significant legal penalties and fines.\n",
      "\n",
      "4. **Prevention of Identity Theft**: Effective data privacy measures help prevent identity theft and fraud, protecting individuals from financial loss and emotional distress.\n",
      "\n",
      "5. **Business Continuity**: Data breaches can disrupt business operations. Ensuring data privacy helps mitigate risks associated with data loss and breaches, contributing to overall business resilience.\n",
      "\n",
      "6. **Ethical Responsibility**: Organizations have an ethical obligation to respect individuals' privacy rights and handle their data responsibly, fostering a culture of accountability.\n",
      "\n",
      "7. **Innovation and Growth**: By establishing robust data privacy practices, companies can innovate and leverage data analytics while maintaining consumer trust, leading to sustainable growth.\n",
      "\n",
      "In summary, data privacy is essential for protecting individuals, maintaining trust, ensuring compliance, and fostering a responsible data-driven environment.\n"
     ]
    }
   ],
   "source": [
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the system and user prompts\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate information.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9: Modify the system_prompt to make the assistant respond in a humorous tone. Observe how the responses change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! Data privacy is like wearing pants in public—it's not just a good idea; it's essential! Here’s why:\n",
      "\n",
      "1. **Personal Space**: Just like you wouldn’t want someone peeking over your shoulder while you’re trying to read a text from your crush, data privacy protects your personal information from unwanted eyes. Nobody wants their embarrassing search history or questionable online purchases broadcasted to the world!\n",
      "\n",
      "2. **Identity Theft**: Imagine someone stealing your identity and then using it to buy a lifetime supply of glittery unicorn pajamas. Not cool, right? Data privacy helps keep your personal information safe from those who might want to impersonate you and make questionable fashion choices in your name.\n",
      "\n",
      "3. **Trust Issues**: In the world of data, trust is like a good Wi-Fi connection—if it’s weak, everything falls apart. When companies respect your data privacy, it builds trust. You’re more likely to share your information if you know it won’t end up in the hands of a data-hungry monster.\n",
      "\n",
      "4. **Legal Protection**: There are laws out there that protect your data privacy, like the GDPR in Europe. Think of it as a superhero cape for your personal information. These laws help keep companies in check, ensuring they don’t treat your data like a piñata at a birthday party.\n",
      "\n",
      "5. **Your Data, Your Rules**: At the end of the day, your data is like your secret recipe for grandma’s famous cookies. You wouldn’t want just anyone to have access to it! Data privacy allows you to control who gets to see your “ingredients” and how they’re used.\n",
      "\n",
      "So, in a nutshell, data privacy is crucial because it keeps your personal information safe, builds trust, prevents identity theft, and gives you control over your data. Plus, it helps you avoid those awkward moments when someone brings up that one time you Googled “how to make a cat dance.” Now, who wouldn’t want that?\n"
     ]
    }
   ],
   "source": [
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the system and user prompts\n",
    "system_prompt = \"You are a humorous assistant that provides information in a witty and funny way.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Utilized prompt\n",
    "how different prompt types—system prompts, user prompts, and assistant prompts—can be utilized in an LLM invocation using the OpenAI API, let's walk through examples in both contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington took office as the first president of the United States on April 30, 1789.\n"
     ]
    }
   ],
   "source": [
    "# Define the conversation with different roles\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in history.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who was the first president of the United States?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"George Washington was the first president of the United States.\"},\n",
    "    {\"role\": \"user\", \"content\": \"When did he take office?\"}\n",
    "]\n",
    "\n",
    "# Get the model's response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Output the assistant's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington took office as the first president of the United States on April 30, 1789. He was elected unanimously by the Electoral College, which reflected the widespread support he had among the American people following his leadership during the American Revolutionary War and his involvement in the drafting of the U.S. Constitution.\n",
      "\n",
      "Washington's presidency was significant as it set many precedents for the future of the office and the federal government. He was seen as a unifying figure in a time when the nation was still new and facing various challenges, including establishing a functioning government and gaining the trust of the public. His decision to step down after two terms also helped to establish the tradition of a two-term limit for presidents, which was later codified in the 22nd Amendment.\n"
     ]
    }
   ],
   "source": [
    "# Define the conversation with different roles\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in history.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who was the first president of the United States?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"That's a good question you ask! You're must be a very studious person. The first president of the great USA is George Washington. Do you find this helpful?\"},\n",
    "    {\"role\": \"user\", \"content\": \"When did he take office? Why?\"}\n",
    "]\n",
    "\n",
    "# Get the model's response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Output the assistant's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Creating an AI Agent\n",
    "An AI agent can perform tasks autonomously based on user instructions. By defining functions and allowing the model to decide when to use them, you can create interactive and functional agents.​\n",
    "\n",
    "Example: AI Agent for Basic Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 minus 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 10: Extend the agent by adding a function that multiplies two numbers. Test the agent with prompts that require multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "    \n",
    "def multiply_numbers(a, b):\n",
    "    return a * b\n",
    "    \n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"multiply_numbers\",\n",
    "                \"description\": \"Multiply two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        elif function_name == \"multiply_numbers\":\n",
    "            result = multiply_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 times 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
